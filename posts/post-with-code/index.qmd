---
title: "Anomaly Detection on Spacecraft Telemetry"
author: "Eric Jackson"
date: "2023-09-08"
categories: [code, analysis]
image: "image.jpg"
toc: true
toc-depth: 2
---

# Background

Spacecraft will generate a massive amount of data the longer they are on orbit, from telemetry data containing voltages, temperatures, etc to raw data from the various types of payloads on orbit

-   Spacecraft have onboard anomaly responses for most known failure cases to safe the vehicle

-   Normally low/high, red/yellow limits set for certain monitors with corresponding response (either automatic or visual alarm)

-   Some anomalies can be hard to predict, multiple components can react slightly out of family to create larger issue

-   Benefits of utilizing machine learning for spacecraft:

-   Prevents loss of mission over potentially high priority targets

-   Automatic response would limit both downtime and human interaction

-   Higher award/incentive fees for lower mission outage percentage

-   Limits time spent by operators and factory investigating and implementing a fix

-   Depending on program and customer, recovery can take anywhere from a few hours to multiple days

-   Predict future anomalous conditions and potentially react before an issue were to occur

-   Some programs have multiple vehicles on orbit meaning there is a plethora of historical training data available

-   Goal: Utilize ARIMA & OCSVM to create a hybrid anomaly detection method and compare results with other common algorithms/methods

![Example of anomaly in telemetry](anomaly.png){width="636"}

# Data Setup & Preprocessing

Unfold below code to see setup. Basics are generating 28 features

setting up training data set and validation data set

```{python}
#| code-fold: true

import os
import datetime
from math import sqrt
import pandas as pd
import numpy as np
from matplotlib import pyplot
from statsmodels.tsa.arima_model import ARIMA
from statsmodels.tsa.statespace.sarimax import SARIMAX
from statsmodels.tsa.stattools import acf, pacf
from statsmodels.tsa.stattools import adfuller
from statsmodels.tsa.seasonal import seasonal_decompose
from statsmodels.tsa.arima_model import ARIMAResults
from sklearn.metrics import mean_squared_error
import sklearn.svm as svm
import matplotlib.pyplot as plt
import math
import warnings
warnings.filterwarnings('ignore', '[\s\w\W]*non-unique[\s\w\W]*', DeprecationWarning)

df=pd.read_csv('./WheelTemperature.csv')
df_battemp=pd.read_csv('./BatteryTemperature.csv')
df_buscurrent=pd.read_csv('./TotalBusCurrent.csv')
df_busvolt=pd.read_csv('./BusVoltage.csv')

df_battemp.Date = pd.to_datetime(df_battemp.Date, format="%m/%d/%Y %H:%M")
df_buscurrent.Date = pd.to_datetime(df_buscurrent.Date, format="%m/%d/%Y")
df_busvolt.Date=pd.to_datetime(df_busvolt.Date, format="%m/%d/%Y %H:%M")
df.Date = pd.to_datetime(df.Date, format="%m/%d/%Y %H:%M")

df_battemp=df_battemp.resample('1D',on='Date').mean()
df_buscurrent=df_buscurrent.resample('1D',on='Date').mean()
df_busvolt=df_busvolt.resample('1D',on='Date').mean()
df_busvolt=df_busvolt.loc['2004-02-13':]
df=df.resample('1D',on='Date').mean()

df=pd.concat([df,df_battemp,df_buscurrent,df_busvolt],axis=1)
df['Date']=df.index

lag_features = ["High", "Low", "Volume", "Turnover", "NumTrades"]
lag_features=["High","Temp","Current","Voltage"]
window1 = 3
window2 = 7
window3 = 30

df_rolled_3d = df[lag_features].rolling(window=window1, min_periods=0)
df_rolled_7d = df[lag_features].rolling(window=window2, min_periods=0)
df_rolled_30d = df[lag_features].rolling(window=window3, min_periods=0)

df_mean_3d = df_rolled_3d.mean().shift(1).reset_index()
df_mean_7d = df_rolled_7d.mean().shift(1).reset_index()
df_mean_30d = df_rolled_30d.mean().shift(1).reset_index()

df_std_3d = df_rolled_3d.std().shift(1).reset_index()
df_std_7d = df_rolled_7d.std().shift(1).reset_index()
df_std_30d = df_rolled_30d.std().shift(1).reset_index()

df_mean_3d.set_index("Date", drop=True, inplace=True)
df_mean_7d.set_index("Date", drop=True, inplace=True)
df_mean_30d.set_index("Date", drop=True, inplace=True)
df_std_3d.set_index("Date", drop=True, inplace=True)
df_std_7d.set_index("Date", drop=True, inplace=True)
df_std_30d.set_index("Date", drop=True, inplace=True)

for feature in lag_features:
    
    df[f"{feature}_mean_lag{window1}"] = df_mean_3d[feature]
    df[f"{feature}_mean_lag{window2}"] = df_mean_7d[feature]
    df[f"{feature}_mean_lag{window3}"] = df_mean_30d[feature]
    
    df[f"{feature}_std_lag{window1}"] = df_std_3d[feature]
    df[f"{feature}_std_lag{window2}"] = df_std_7d[feature]
    df[f"{feature}_std_lag{window3}"] = df_std_30d[feature]

df.Date = pd.to_datetime(df.Date, format="%m/%d/%Y %H:%M")
df["month"] = df.Date.dt.month
df["week"] = df.Date.dt.isocalendar().week.astype(np.int64)
df["day"] = df.Date.dt.day
df["day_of_week"] = df.Date.dt.dayofweek
df.set_index("Date", drop=True, inplace=True)
df.fillna(df.mean(), inplace=True)

data=df
data.index = pd.to_datetime(data.index)
data=data.resample('1D').mean()
df_train=data.iloc[0:math.floor(len(data)*.75),:]
df_valid=data.iloc[math.floor(len(data)*.75):,:]

exogenous_features=['High_mean_lag3', 'High_mean_lag7',
       'High_mean_lag30', 'High_std_lag3', 'High_std_lag7', 'High_std_lag30',
       'Temp_mean_lag3', 'Temp_mean_lag7', 'Temp_mean_lag30', 'Temp_std_lag3',
       'Temp_std_lag7', 'Temp_std_lag30', 'Current_mean_lag3',
       'Current_mean_lag7', 'Current_mean_lag30', 'Current_std_lag3',
       'Current_std_lag7', 'Current_std_lag30', 'Voltage_mean_lag3',
       'Voltage_mean_lag7', 'Voltage_mean_lag30', 'Voltage_std_lag3',
       'Voltage_std_lag7', 'Voltage_std_lag30', 'month', 'week', 'day',
       'day_of_week']
       
       
#exogenous_features=['High_mean_lag3','week']
      
```

# ARIMA Model

```{python}
from pmdarima import auto_arima
from sklearn.metrics import mean_absolute_error

model = auto_arima(
	df_train["High"],
	exogenous=df_train[exogenous_features],
	trace=True,
	error_action="ignore",
	suppress_warnings=True,
    seasonal=True,
    m=1)
model.fit(df_train.High, exogenous=df_train[exogenous_features])
forecast = model.predict(n_periods=len(df_valid), exogenous=df_valid[exogenous_features])
df_valid.insert(len(df_valid.columns),"Forecast_ARIMAX",forecast,True)

print("\nRMSE of Auto ARIMAX:", np.sqrt(mean_squared_error(df_valid.High, df_valid.Forecast_ARIMAX)))
print("\nMAE of Auto ARIMAX:", mean_absolute_error(df_valid.High, df_valid.Forecast_ARIMAX))
```

@fig-arima

```{python}
#| echo: False 
#| fig-width: 30%
#| label: fig-arima
#| fig-cap: "Initial ARIMA forecast on reaction wheel temperature data"
df_valid[["High", "Forecast_ARIMAX"]].plot(figsize=(14, 7))
plt.legend(['Wheel Temperature','Forecast (ARIMA)'])
plt.show()
```

```{python}
fig, ax = plt.subplots(figsize=(10,6))
plt.plot(df_train["High"])
plt.plot(df_valid["Forecast_ARIMAX"])
plt.legend(['Training Data','Test Data'],loc='best')
plt.ylabel('Temperature (C)')
plt.show()

fig, ax = plt.subplots(figsize=(10,6))
plt.plot(df_valid["High"])
plt.plot(df_valid["Forecast_ARIMAX"])
plt.legend(['Truth','ARIMA Model'],loc='lower left')
plt.ylabel('Temperature (C)')
plt.show()

```

```{python}
############ Truth ################

df_truth=pd.read_csv('./truth.csv')
df_truth.Date = pd.to_datetime(df_truth.Date, format="%m/%d/%Y")
df_truth.set_index("Date", drop=True, inplace=True)
anom=df_truth['Anom']
anom=anom.map(lambda val:1 if val==-1 else 0)
a=df_truth.loc[df_truth['Anom']==1,['High']]
fig, ax = plt.subplots(figsize=(10,6))
ax.plot(df_truth.index,df_truth['High'], color='black', label = 'ARIMA')
ax.scatter(a.index,a.values, color='red', label = 'Anomaly')
plt.legend(['Wheel Temperature','Anomaly'])
plt.ylabel('Temperature (C)')
plt.title('Truth Anomalies')
plt.show()
```

# OCSVM

One class support vector machine algorithm

![OCSVM](https://www.researchgate.net/publication/362912442/figure/fig4/AS:11431281080912015@1661430301368/Schematic-of-the-OCSVM_W640.jpg){width="408"}

```{python}
############# OCSVM ##################

fig, ax = plt.subplots(figsize=(10,6))
data2=df_valid["Forecast_ARIMAX"]
model =svm.OneClassSVM(nu=0.05,kernel='poly')
model.fit(data2.values.reshape(-1,1))
anom=(pd.Series(model.predict(data2.values.reshape(-1,1))))
df2=pd.DataFrame()
df2['Time']=data2.index
df2['data']=data2.values
df2['anom']=anom
a=df2.loc[df2['anom']==-1,['Time','data']]
df2.set_index("Time", drop=True, inplace=True)
ax.plot(df2.index, df2['data'], color='black', label = 'ARIMA')
ax.scatter(a['Time'].values,a['data'], color='red', label = 'Anomaly')
plt.legend(['Wheel Temperature','Anomaly'])
plt.ylabel('Temperature (C)')
plt.title('Anomalies detected with OCSVM')
plt.show()
```

# Isolation Forest

```{python}
######### Isolation Forest ################
import sklearn
from sklearn.ensemble import IsolationForest
isofor=df_valid
outliers_fraction = float(.01)
scaler = sklearn.preprocessing.StandardScaler()
np_scaled = scaler.fit_transform(isofor['Forecast_ARIMAX'].values.reshape(-1, 1))
data = pd.DataFrame(np_scaled)
# train isolation forest
model =  IsolationForest(contamination=outliers_fraction)
model.fit(data)



isofor['anomaly'] = model.predict(data)
# visualization
fig, ax = plt.subplots(figsize=(10,6))
a = isofor.loc[isofor['anomaly'] == -1, ['Forecast_ARIMAX']] #anomaly
ax.plot(isofor.index, isofor['Forecast_ARIMAX'], color='black', label = 'Normal')
ax.scatter(a.index,a['Forecast_ARIMAX'], color='red', label = 'Anomaly')
plt.legend(['Wheel Temperature','Anomaly'])
plt.ylabel('Temperature (C)')
plt.title('Anomalies detected with Isolation Forest')
plt.show()
```

# Final Results

```{python}
#| code-fold: true
######################### calculate statistics ###########################
from sklearn.metrics import f1_score,recall_score,precision_score
from sklearn.metrics import mean_squared_error
from tabulate import tabulate
from collections import OrderedDict
from sklearn.metrics import precision_recall_curve
from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.metrics import confusion_matrix
from numpy import array

def perf_measure(y_actual, y_hat):
    TP = 0
    FP = 0
    TN = 0
    FN = 0

    for i in range(len(y_hat)): 
        if y_actual[i]==y_hat[i]==1:
           TP += 1
        if y_hat[i]==1 and y_actual[i]!=y_hat[i]:
           FP += 1
        if y_actual[i]==y_hat[i]==0:
           TN += 1
        if y_hat[i]==0 and y_actual[i]!=y_hat[i]:
           FN += 1

    return(TP, FP, TN, FN)
```

```{python}
df_truth=pd.read_csv('./truth.csv')
anom=anom.map(lambda val:1 if val==-1 else 0)
#calculate F1 score
f1=f1_score(df_truth['Anom'].values, anom.values)
rec=recall_score(df_truth['Anom'].values, anom.values)
prec=precision_score(df_truth['Anom'].values, anom.values)
TP, FP, TN, FN=perf_measure(df_truth['Anom'].values, anom.values)
fpr=FP/(TN+FP)
final=OrderedDict()
final['OCSVM']=[f1,rec,prec,fpr]

a2=isofor['anomaly']
a2=a2.map(lambda val:1 if val==-1 else 0)
f1=f1_score(df_truth['Anom'].values, a2.values)
rec=recall_score(df_truth['Anom'].values, a2.values)
prec=precision_score(df_truth['Anom'].values, a2.values)
TP, FP, TN, FN=perf_measure(df_truth['Anom'].values, a2.values)
fpr=FP/(TN+FP)
final['IsoFor']=[f1,rec,prec,fpr]
df=pd.DataFrame(final)
df.index=['F1','Recall','Precision','FPR']
print(tabulate(df, headers='keys', tablefmt='psql'))

cm=confusion_matrix(df_truth['Anom'].values,anom.values)
cmd=ConfusionMatrixDisplay(cm)
cmd.plot()
plt.show()

cm=confusion_matrix(df_truth['Anom'].values,a2.values)
cmd=ConfusionMatrixDisplay(cm)
cmd.plot()
plt.show()
```
