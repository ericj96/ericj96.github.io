{"title":"Anomaly Detection on Spacecraft Telemetry","markdown":{"yaml":{"title":"Anomaly Detection on Spacecraft Telemetry","author":"Eric Jackson","date":"2023-09-08","categories":["code","analysis"],"image":"image.jpg","toc":true,"toc-depth":2},"headingText":"Background","containsRefs":false,"markdown":"\n\n\nSpacecraft will generate a massive amount of data the longer they are on orbit, from telemetry data containing voltages, temperatures, etc to raw data from the various types of payloads on orbit\n\n-   Spacecraft have onboard anomaly responses for most known failure cases to safe the vehicle\n\n-   Normally low/high, red/yellow limits set for certain monitors with corresponding response (either automatic or visual alarm)\n\n-   Some anomalies can be hard to predict, multiple components can react slightly out of family to create larger issue\n\n-   Benefits of utilizing machine learning for spacecraft:\n\n-   Prevents loss of mission over potentially high priority targets\n\n-   Automatic response would limit both downtime and human interaction\n\n-   Higher award/incentive fees for lower mission outage percentage\n\n-   Limits time spent by operators and factory investigating and implementing a fix\n\n-   Depending on program and customer, recovery can take anywhere from a few hours to multiple days\n\n-   Predict future anomalous conditions and potentially react before an issue were to occur\n\n-   Some programs have multiple vehicles on orbit meaning there is a plethora of historical training data available\n\n-   Goal: Utilize ARIMA & OCSVM to create a hybrid anomaly detection method and compare results with other common algorithms/methods\n\n![Example of anomaly in telemetry](anomaly.png){width=\"636\"}\n\n# Data Setup & Preprocessing\n\nUnfold below code to see setup. Basics are generating 28 features\n\nsetting up training data set and validation data set\n\n```{python}\n#| code-fold: true\n\nimport os\nimport datetime\nfrom math import sqrt\nimport pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot\nfrom statsmodels.tsa.arima_model import ARIMA\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\nfrom statsmodels.tsa.stattools import acf, pacf\nfrom statsmodels.tsa.stattools import adfuller\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nfrom statsmodels.tsa.arima_model import ARIMAResults\nfrom sklearn.metrics import mean_squared_error\nimport sklearn.svm as svm\nimport matplotlib.pyplot as plt\nimport math\nimport warnings\nwarnings.filterwarnings('ignore', '[\\s\\w\\W]*non-unique[\\s\\w\\W]*', DeprecationWarning)\n\ndf=pd.read_csv('./WheelTemperature.csv')\ndf_battemp=pd.read_csv('./BatteryTemperature.csv')\ndf_buscurrent=pd.read_csv('./TotalBusCurrent.csv')\ndf_busvolt=pd.read_csv('./BusVoltage.csv')\n\ndf_battemp.Date = pd.to_datetime(df_battemp.Date, format=\"%m/%d/%Y %H:%M\")\ndf_buscurrent.Date = pd.to_datetime(df_buscurrent.Date, format=\"%m/%d/%Y\")\ndf_busvolt.Date=pd.to_datetime(df_busvolt.Date, format=\"%m/%d/%Y %H:%M\")\ndf.Date = pd.to_datetime(df.Date, format=\"%m/%d/%Y %H:%M\")\n\ndf_battemp=df_battemp.resample('1D',on='Date').mean()\ndf_buscurrent=df_buscurrent.resample('1D',on='Date').mean()\ndf_busvolt=df_busvolt.resample('1D',on='Date').mean()\ndf_busvolt=df_busvolt.loc['2004-02-13':]\ndf=df.resample('1D',on='Date').mean()\n\ndf=pd.concat([df,df_battemp,df_buscurrent,df_busvolt],axis=1)\ndf['Date']=df.index\n\nlag_features = [\"High\", \"Low\", \"Volume\", \"Turnover\", \"NumTrades\"]\nlag_features=[\"High\",\"Temp\",\"Current\",\"Voltage\"]\nwindow1 = 3\nwindow2 = 7\nwindow3 = 30\n\ndf_rolled_3d = df[lag_features].rolling(window=window1, min_periods=0)\ndf_rolled_7d = df[lag_features].rolling(window=window2, min_periods=0)\ndf_rolled_30d = df[lag_features].rolling(window=window3, min_periods=0)\n\ndf_mean_3d = df_rolled_3d.mean().shift(1).reset_index()\ndf_mean_7d = df_rolled_7d.mean().shift(1).reset_index()\ndf_mean_30d = df_rolled_30d.mean().shift(1).reset_index()\n\ndf_std_3d = df_rolled_3d.std().shift(1).reset_index()\ndf_std_7d = df_rolled_7d.std().shift(1).reset_index()\ndf_std_30d = df_rolled_30d.std().shift(1).reset_index()\n\ndf_mean_3d.set_index(\"Date\", drop=True, inplace=True)\ndf_mean_7d.set_index(\"Date\", drop=True, inplace=True)\ndf_mean_30d.set_index(\"Date\", drop=True, inplace=True)\ndf_std_3d.set_index(\"Date\", drop=True, inplace=True)\ndf_std_7d.set_index(\"Date\", drop=True, inplace=True)\ndf_std_30d.set_index(\"Date\", drop=True, inplace=True)\n\nfor feature in lag_features:\n    \n    df[f\"{feature}_mean_lag{window1}\"] = df_mean_3d[feature]\n    df[f\"{feature}_mean_lag{window2}\"] = df_mean_7d[feature]\n    df[f\"{feature}_mean_lag{window3}\"] = df_mean_30d[feature]\n    \n    df[f\"{feature}_std_lag{window1}\"] = df_std_3d[feature]\n    df[f\"{feature}_std_lag{window2}\"] = df_std_7d[feature]\n    df[f\"{feature}_std_lag{window3}\"] = df_std_30d[feature]\n\ndf.Date = pd.to_datetime(df.Date, format=\"%m/%d/%Y %H:%M\")\ndf[\"month\"] = df.Date.dt.month\ndf[\"week\"] = df.Date.dt.isocalendar().week.astype(np.int64)\ndf[\"day\"] = df.Date.dt.day\ndf[\"day_of_week\"] = df.Date.dt.dayofweek\ndf.set_index(\"Date\", drop=True, inplace=True)\ndf.fillna(df.mean(), inplace=True)\n\ndata=df\ndata.index = pd.to_datetime(data.index)\ndata=data.resample('1D').mean()\ndf_train=data.iloc[0:math.floor(len(data)*.75),:]\ndf_valid=data.iloc[math.floor(len(data)*.75):,:]\n\nexogenous_features=['High_mean_lag3', 'High_mean_lag7',\n       'High_mean_lag30', 'High_std_lag3', 'High_std_lag7', 'High_std_lag30',\n       'Temp_mean_lag3', 'Temp_mean_lag7', 'Temp_mean_lag30', 'Temp_std_lag3',\n       'Temp_std_lag7', 'Temp_std_lag30', 'Current_mean_lag3',\n       'Current_mean_lag7', 'Current_mean_lag30', 'Current_std_lag3',\n       'Current_std_lag7', 'Current_std_lag30', 'Voltage_mean_lag3',\n       'Voltage_mean_lag7', 'Voltage_mean_lag30', 'Voltage_std_lag3',\n       'Voltage_std_lag7', 'Voltage_std_lag30', 'month', 'week', 'day',\n       'day_of_week']\n       \n       \n#exogenous_features=['High_mean_lag3','week']\n      \n```\n\n# ARIMA Model\n\n```{python}\nfrom pmdarima import auto_arima\nfrom sklearn.metrics import mean_absolute_error\n\nmodel = auto_arima(\n\tdf_train[\"High\"],\n\texogenous=df_train[exogenous_features],\n\ttrace=True,\n\terror_action=\"ignore\",\n\tsuppress_warnings=True,\n    seasonal=True,\n    m=1)\nmodel.fit(df_train.High, exogenous=df_train[exogenous_features])\nforecast = model.predict(n_periods=len(df_valid), exogenous=df_valid[exogenous_features])\ndf_valid.insert(len(df_valid.columns),\"Forecast_ARIMAX\",forecast,True)\n\nprint(\"\\nRMSE of Auto ARIMAX:\", np.sqrt(mean_squared_error(df_valid.High, df_valid.Forecast_ARIMAX)))\nprint(\"\\nMAE of Auto ARIMAX:\", mean_absolute_error(df_valid.High, df_valid.Forecast_ARIMAX))\n```\n\n@fig-arima\n\n```{python}\n#| echo: False \n#| fig-width: 30%\n#| label: fig-arima\n#| fig-cap: \"Initial ARIMA forecast on reaction wheel temperature data\"\ndf_valid[[\"High\", \"Forecast_ARIMAX\"]].plot(figsize=(14, 7))\nplt.legend(['Wheel Temperature','Forecast (ARIMA)'])\nplt.show()\n```\n\n```{python}\nfig, ax = plt.subplots(figsize=(10,6))\nplt.plot(df_train[\"High\"])\nplt.plot(df_valid[\"Forecast_ARIMAX\"])\nplt.legend(['Training Data','Test Data'],loc='best')\nplt.ylabel('Temperature (C)')\nplt.show()\n\nfig, ax = plt.subplots(figsize=(10,6))\nplt.plot(df_valid[\"High\"])\nplt.plot(df_valid[\"Forecast_ARIMAX\"])\nplt.legend(['Truth','ARIMA Model'],loc='lower left')\nplt.ylabel('Temperature (C)')\nplt.show()\n\n```\n\n```{python}\n############ Truth ################\n\ndf_truth=pd.read_csv('./truth.csv')\ndf_truth.Date = pd.to_datetime(df_truth.Date, format=\"%m/%d/%Y\")\ndf_truth.set_index(\"Date\", drop=True, inplace=True)\nanom=df_truth['Anom']\nanom=anom.map(lambda val:1 if val==-1 else 0)\na=df_truth.loc[df_truth['Anom']==1,['High']]\nfig, ax = plt.subplots(figsize=(10,6))\nax.plot(df_truth.index,df_truth['High'], color='black', label = 'ARIMA')\nax.scatter(a.index,a.values, color='red', label = 'Anomaly')\nplt.legend(['Wheel Temperature','Anomaly'])\nplt.ylabel('Temperature (C)')\nplt.title('Truth Anomalies')\nplt.show()\n```\n\n# OCSVM\n\nOne class support vector machine algorithm\n\n![OCSVM](https://www.researchgate.net/publication/362912442/figure/fig4/AS:11431281080912015@1661430301368/Schematic-of-the-OCSVM_W640.jpg){width=\"408\"}\n\n```{python}\n############# OCSVM ##################\n\nfig, ax = plt.subplots(figsize=(10,6))\ndata2=df_valid[\"Forecast_ARIMAX\"]\nmodel =svm.OneClassSVM(nu=0.05,kernel='poly')\nmodel.fit(data2.values.reshape(-1,1))\nanom=(pd.Series(model.predict(data2.values.reshape(-1,1))))\ndf2=pd.DataFrame()\ndf2['Time']=data2.index\ndf2['data']=data2.values\ndf2['anom']=anom\na=df2.loc[df2['anom']==-1,['Time','data']]\ndf2.set_index(\"Time\", drop=True, inplace=True)\nax.plot(df2.index, df2['data'], color='black', label = 'ARIMA')\nax.scatter(a['Time'].values,a['data'], color='red', label = 'Anomaly')\nplt.legend(['Wheel Temperature','Anomaly'])\nplt.ylabel('Temperature (C)')\nplt.title('Anomalies detected with OCSVM')\nplt.show()\n```\n\n# Isolation Forest\n\n```{python}\n######### Isolation Forest ################\nimport sklearn\nfrom sklearn.ensemble import IsolationForest\ncatfish_sales=df_valid\noutliers_fraction = float(.01)\nscaler = sklearn.preprocessing.StandardScaler()\nnp_scaled = scaler.fit_transform(catfish_sales['Forecast_ARIMAX'].values.reshape(-1, 1))\ndata = pd.DataFrame(np_scaled)\n# train isolation forest\nmodel =  IsolationForest(contamination=outliers_fraction)\nmodel.fit(data)\n\n\n\ncatfish_sales['anomaly'] = model.predict(data)\n# visualization\nfig, ax = plt.subplots(figsize=(10,6))\na = catfish_sales.loc[catfish_sales['anomaly'] == -1, ['Forecast_ARIMAX']] #anomaly\nax.plot(catfish_sales.index, catfish_sales['Forecast_ARIMAX'], color='black', label = 'Normal')\nax.scatter(a.index,a['Forecast_ARIMAX'], color='red', label = 'Anomaly')\nplt.legend(['Wheel Temperature','Anomaly'])\nplt.ylabel('Temperature (C)')\nplt.title('Anomalies detected with Isolation Forest')\nplt.show()\n```\n\n# Final Results\n\n```{python}\n######################### calculate statistics ###########################\nfrom sklearn.metrics import f1_score,recall_score,precision_score\nfrom sklearn.metrics import mean_squared_error\nfrom tabulate import tabulate\nfrom collections import OrderedDict\nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import ConfusionMatrixDisplay\nfrom sklearn.metrics import confusion_matrix\nfrom numpy import array\n\ndef perf_measure(y_actual, y_hat):\n    TP = 0\n    FP = 0\n    TN = 0\n    FN = 0\n\n    for i in range(len(y_hat)): \n        if y_actual[i]==y_hat[i]==1:\n           TP += 1\n        if y_hat[i]==1 and y_actual[i]!=y_hat[i]:\n           FP += 1\n        if y_actual[i]==y_hat[i]==0:\n           TN += 1\n        if y_hat[i]==0 and y_actual[i]!=y_hat[i]:\n           FN += 1\n\n    return(TP, FP, TN, FN)\n\ndf_truth=pd.read_csv('./truth.csv')\nanom=anom.map(lambda val:1 if val==-1 else 0)\n#calculate F1 score\nf1=f1_score(df_truth['Anom'].values, anom.values)\nrec=recall_score(df_truth['Anom'].values, anom.values)\nprec=precision_score(df_truth['Anom'].values, anom.values)\nTP, FP, TN, FN=perf_measure(df_truth['Anom'].values, anom.values)\nfpr=FP/(TN+FP)\nfinal=OrderedDict()\nfinal['OCSVM']=[f1,rec,prec,fpr]\n\na2=catfish_sales['anomaly']\na2=a2.map(lambda val:1 if val==-1 else 0)\nf1=f1_score(df_truth['Anom'].values, a2.values)\nrec=recall_score(df_truth['Anom'].values, a2.values)\nprec=precision_score(df_truth['Anom'].values, a2.values)\nTP, FP, TN, FN=perf_measure(df_truth['Anom'].values, a2.values)\nfpr=FP/(TN+FP)\nfinal['IsoFor']=[f1,rec,prec,fpr]\ndf=pd.DataFrame(final)\ndf.index=['F1','Recall','Precision','FPR']\nprint(tabulate(df, headers='keys', tablefmt='psql'))\n\n#cm=np.array([TP,FP],[FN,TN])\ncm=confusion_matrix(df_truth['Anom'].values,a2.values)\ncmd=ConfusionMatrixDisplay(cm)\ncmd.plot()\nplt.show()\n```\n","srcMarkdownNoYaml":"\n\n# Background\n\nSpacecraft will generate a massive amount of data the longer they are on orbit, from telemetry data containing voltages, temperatures, etc to raw data from the various types of payloads on orbit\n\n-   Spacecraft have onboard anomaly responses for most known failure cases to safe the vehicle\n\n-   Normally low/high, red/yellow limits set for certain monitors with corresponding response (either automatic or visual alarm)\n\n-   Some anomalies can be hard to predict, multiple components can react slightly out of family to create larger issue\n\n-   Benefits of utilizing machine learning for spacecraft:\n\n-   Prevents loss of mission over potentially high priority targets\n\n-   Automatic response would limit both downtime and human interaction\n\n-   Higher award/incentive fees for lower mission outage percentage\n\n-   Limits time spent by operators and factory investigating and implementing a fix\n\n-   Depending on program and customer, recovery can take anywhere from a few hours to multiple days\n\n-   Predict future anomalous conditions and potentially react before an issue were to occur\n\n-   Some programs have multiple vehicles on orbit meaning there is a plethora of historical training data available\n\n-   Goal: Utilize ARIMA & OCSVM to create a hybrid anomaly detection method and compare results with other common algorithms/methods\n\n![Example of anomaly in telemetry](anomaly.png){width=\"636\"}\n\n# Data Setup & Preprocessing\n\nUnfold below code to see setup. Basics are generating 28 features\n\nsetting up training data set and validation data set\n\n```{python}\n#| code-fold: true\n\nimport os\nimport datetime\nfrom math import sqrt\nimport pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot\nfrom statsmodels.tsa.arima_model import ARIMA\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\nfrom statsmodels.tsa.stattools import acf, pacf\nfrom statsmodels.tsa.stattools import adfuller\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nfrom statsmodels.tsa.arima_model import ARIMAResults\nfrom sklearn.metrics import mean_squared_error\nimport sklearn.svm as svm\nimport matplotlib.pyplot as plt\nimport math\nimport warnings\nwarnings.filterwarnings('ignore', '[\\s\\w\\W]*non-unique[\\s\\w\\W]*', DeprecationWarning)\n\ndf=pd.read_csv('./WheelTemperature.csv')\ndf_battemp=pd.read_csv('./BatteryTemperature.csv')\ndf_buscurrent=pd.read_csv('./TotalBusCurrent.csv')\ndf_busvolt=pd.read_csv('./BusVoltage.csv')\n\ndf_battemp.Date = pd.to_datetime(df_battemp.Date, format=\"%m/%d/%Y %H:%M\")\ndf_buscurrent.Date = pd.to_datetime(df_buscurrent.Date, format=\"%m/%d/%Y\")\ndf_busvolt.Date=pd.to_datetime(df_busvolt.Date, format=\"%m/%d/%Y %H:%M\")\ndf.Date = pd.to_datetime(df.Date, format=\"%m/%d/%Y %H:%M\")\n\ndf_battemp=df_battemp.resample('1D',on='Date').mean()\ndf_buscurrent=df_buscurrent.resample('1D',on='Date').mean()\ndf_busvolt=df_busvolt.resample('1D',on='Date').mean()\ndf_busvolt=df_busvolt.loc['2004-02-13':]\ndf=df.resample('1D',on='Date').mean()\n\ndf=pd.concat([df,df_battemp,df_buscurrent,df_busvolt],axis=1)\ndf['Date']=df.index\n\nlag_features = [\"High\", \"Low\", \"Volume\", \"Turnover\", \"NumTrades\"]\nlag_features=[\"High\",\"Temp\",\"Current\",\"Voltage\"]\nwindow1 = 3\nwindow2 = 7\nwindow3 = 30\n\ndf_rolled_3d = df[lag_features].rolling(window=window1, min_periods=0)\ndf_rolled_7d = df[lag_features].rolling(window=window2, min_periods=0)\ndf_rolled_30d = df[lag_features].rolling(window=window3, min_periods=0)\n\ndf_mean_3d = df_rolled_3d.mean().shift(1).reset_index()\ndf_mean_7d = df_rolled_7d.mean().shift(1).reset_index()\ndf_mean_30d = df_rolled_30d.mean().shift(1).reset_index()\n\ndf_std_3d = df_rolled_3d.std().shift(1).reset_index()\ndf_std_7d = df_rolled_7d.std().shift(1).reset_index()\ndf_std_30d = df_rolled_30d.std().shift(1).reset_index()\n\ndf_mean_3d.set_index(\"Date\", drop=True, inplace=True)\ndf_mean_7d.set_index(\"Date\", drop=True, inplace=True)\ndf_mean_30d.set_index(\"Date\", drop=True, inplace=True)\ndf_std_3d.set_index(\"Date\", drop=True, inplace=True)\ndf_std_7d.set_index(\"Date\", drop=True, inplace=True)\ndf_std_30d.set_index(\"Date\", drop=True, inplace=True)\n\nfor feature in lag_features:\n    \n    df[f\"{feature}_mean_lag{window1}\"] = df_mean_3d[feature]\n    df[f\"{feature}_mean_lag{window2}\"] = df_mean_7d[feature]\n    df[f\"{feature}_mean_lag{window3}\"] = df_mean_30d[feature]\n    \n    df[f\"{feature}_std_lag{window1}\"] = df_std_3d[feature]\n    df[f\"{feature}_std_lag{window2}\"] = df_std_7d[feature]\n    df[f\"{feature}_std_lag{window3}\"] = df_std_30d[feature]\n\ndf.Date = pd.to_datetime(df.Date, format=\"%m/%d/%Y %H:%M\")\ndf[\"month\"] = df.Date.dt.month\ndf[\"week\"] = df.Date.dt.isocalendar().week.astype(np.int64)\ndf[\"day\"] = df.Date.dt.day\ndf[\"day_of_week\"] = df.Date.dt.dayofweek\ndf.set_index(\"Date\", drop=True, inplace=True)\ndf.fillna(df.mean(), inplace=True)\n\ndata=df\ndata.index = pd.to_datetime(data.index)\ndata=data.resample('1D').mean()\ndf_train=data.iloc[0:math.floor(len(data)*.75),:]\ndf_valid=data.iloc[math.floor(len(data)*.75):,:]\n\nexogenous_features=['High_mean_lag3', 'High_mean_lag7',\n       'High_mean_lag30', 'High_std_lag3', 'High_std_lag7', 'High_std_lag30',\n       'Temp_mean_lag3', 'Temp_mean_lag7', 'Temp_mean_lag30', 'Temp_std_lag3',\n       'Temp_std_lag7', 'Temp_std_lag30', 'Current_mean_lag3',\n       'Current_mean_lag7', 'Current_mean_lag30', 'Current_std_lag3',\n       'Current_std_lag7', 'Current_std_lag30', 'Voltage_mean_lag3',\n       'Voltage_mean_lag7', 'Voltage_mean_lag30', 'Voltage_std_lag3',\n       'Voltage_std_lag7', 'Voltage_std_lag30', 'month', 'week', 'day',\n       'day_of_week']\n       \n       \n#exogenous_features=['High_mean_lag3','week']\n      \n```\n\n# ARIMA Model\n\n```{python}\nfrom pmdarima import auto_arima\nfrom sklearn.metrics import mean_absolute_error\n\nmodel = auto_arima(\n\tdf_train[\"High\"],\n\texogenous=df_train[exogenous_features],\n\ttrace=True,\n\terror_action=\"ignore\",\n\tsuppress_warnings=True,\n    seasonal=True,\n    m=1)\nmodel.fit(df_train.High, exogenous=df_train[exogenous_features])\nforecast = model.predict(n_periods=len(df_valid), exogenous=df_valid[exogenous_features])\ndf_valid.insert(len(df_valid.columns),\"Forecast_ARIMAX\",forecast,True)\n\nprint(\"\\nRMSE of Auto ARIMAX:\", np.sqrt(mean_squared_error(df_valid.High, df_valid.Forecast_ARIMAX)))\nprint(\"\\nMAE of Auto ARIMAX:\", mean_absolute_error(df_valid.High, df_valid.Forecast_ARIMAX))\n```\n\n@fig-arima\n\n```{python}\n#| echo: False \n#| fig-width: 30%\n#| label: fig-arima\n#| fig-cap: \"Initial ARIMA forecast on reaction wheel temperature data\"\ndf_valid[[\"High\", \"Forecast_ARIMAX\"]].plot(figsize=(14, 7))\nplt.legend(['Wheel Temperature','Forecast (ARIMA)'])\nplt.show()\n```\n\n```{python}\nfig, ax = plt.subplots(figsize=(10,6))\nplt.plot(df_train[\"High\"])\nplt.plot(df_valid[\"Forecast_ARIMAX\"])\nplt.legend(['Training Data','Test Data'],loc='best')\nplt.ylabel('Temperature (C)')\nplt.show()\n\nfig, ax = plt.subplots(figsize=(10,6))\nplt.plot(df_valid[\"High\"])\nplt.plot(df_valid[\"Forecast_ARIMAX\"])\nplt.legend(['Truth','ARIMA Model'],loc='lower left')\nplt.ylabel('Temperature (C)')\nplt.show()\n\n```\n\n```{python}\n############ Truth ################\n\ndf_truth=pd.read_csv('./truth.csv')\ndf_truth.Date = pd.to_datetime(df_truth.Date, format=\"%m/%d/%Y\")\ndf_truth.set_index(\"Date\", drop=True, inplace=True)\nanom=df_truth['Anom']\nanom=anom.map(lambda val:1 if val==-1 else 0)\na=df_truth.loc[df_truth['Anom']==1,['High']]\nfig, ax = plt.subplots(figsize=(10,6))\nax.plot(df_truth.index,df_truth['High'], color='black', label = 'ARIMA')\nax.scatter(a.index,a.values, color='red', label = 'Anomaly')\nplt.legend(['Wheel Temperature','Anomaly'])\nplt.ylabel('Temperature (C)')\nplt.title('Truth Anomalies')\nplt.show()\n```\n\n# OCSVM\n\nOne class support vector machine algorithm\n\n![OCSVM](https://www.researchgate.net/publication/362912442/figure/fig4/AS:11431281080912015@1661430301368/Schematic-of-the-OCSVM_W640.jpg){width=\"408\"}\n\n```{python}\n############# OCSVM ##################\n\nfig, ax = plt.subplots(figsize=(10,6))\ndata2=df_valid[\"Forecast_ARIMAX\"]\nmodel =svm.OneClassSVM(nu=0.05,kernel='poly')\nmodel.fit(data2.values.reshape(-1,1))\nanom=(pd.Series(model.predict(data2.values.reshape(-1,1))))\ndf2=pd.DataFrame()\ndf2['Time']=data2.index\ndf2['data']=data2.values\ndf2['anom']=anom\na=df2.loc[df2['anom']==-1,['Time','data']]\ndf2.set_index(\"Time\", drop=True, inplace=True)\nax.plot(df2.index, df2['data'], color='black', label = 'ARIMA')\nax.scatter(a['Time'].values,a['data'], color='red', label = 'Anomaly')\nplt.legend(['Wheel Temperature','Anomaly'])\nplt.ylabel('Temperature (C)')\nplt.title('Anomalies detected with OCSVM')\nplt.show()\n```\n\n# Isolation Forest\n\n```{python}\n######### Isolation Forest ################\nimport sklearn\nfrom sklearn.ensemble import IsolationForest\ncatfish_sales=df_valid\noutliers_fraction = float(.01)\nscaler = sklearn.preprocessing.StandardScaler()\nnp_scaled = scaler.fit_transform(catfish_sales['Forecast_ARIMAX'].values.reshape(-1, 1))\ndata = pd.DataFrame(np_scaled)\n# train isolation forest\nmodel =  IsolationForest(contamination=outliers_fraction)\nmodel.fit(data)\n\n\n\ncatfish_sales['anomaly'] = model.predict(data)\n# visualization\nfig, ax = plt.subplots(figsize=(10,6))\na = catfish_sales.loc[catfish_sales['anomaly'] == -1, ['Forecast_ARIMAX']] #anomaly\nax.plot(catfish_sales.index, catfish_sales['Forecast_ARIMAX'], color='black', label = 'Normal')\nax.scatter(a.index,a['Forecast_ARIMAX'], color='red', label = 'Anomaly')\nplt.legend(['Wheel Temperature','Anomaly'])\nplt.ylabel('Temperature (C)')\nplt.title('Anomalies detected with Isolation Forest')\nplt.show()\n```\n\n# Final Results\n\n```{python}\n######################### calculate statistics ###########################\nfrom sklearn.metrics import f1_score,recall_score,precision_score\nfrom sklearn.metrics import mean_squared_error\nfrom tabulate import tabulate\nfrom collections import OrderedDict\nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import ConfusionMatrixDisplay\nfrom sklearn.metrics import confusion_matrix\nfrom numpy import array\n\ndef perf_measure(y_actual, y_hat):\n    TP = 0\n    FP = 0\n    TN = 0\n    FN = 0\n\n    for i in range(len(y_hat)): \n        if y_actual[i]==y_hat[i]==1:\n           TP += 1\n        if y_hat[i]==1 and y_actual[i]!=y_hat[i]:\n           FP += 1\n        if y_actual[i]==y_hat[i]==0:\n           TN += 1\n        if y_hat[i]==0 and y_actual[i]!=y_hat[i]:\n           FN += 1\n\n    return(TP, FP, TN, FN)\n\ndf_truth=pd.read_csv('./truth.csv')\nanom=anom.map(lambda val:1 if val==-1 else 0)\n#calculate F1 score\nf1=f1_score(df_truth['Anom'].values, anom.values)\nrec=recall_score(df_truth['Anom'].values, anom.values)\nprec=precision_score(df_truth['Anom'].values, anom.values)\nTP, FP, TN, FN=perf_measure(df_truth['Anom'].values, anom.values)\nfpr=FP/(TN+FP)\nfinal=OrderedDict()\nfinal['OCSVM']=[f1,rec,prec,fpr]\n\na2=catfish_sales['anomaly']\na2=a2.map(lambda val:1 if val==-1 else 0)\nf1=f1_score(df_truth['Anom'].values, a2.values)\nrec=recall_score(df_truth['Anom'].values, a2.values)\nprec=precision_score(df_truth['Anom'].values, a2.values)\nTP, FP, TN, FN=perf_measure(df_truth['Anom'].values, a2.values)\nfpr=FP/(TN+FP)\nfinal['IsoFor']=[f1,rec,prec,fpr]\ndf=pd.DataFrame(final)\ndf.index=['F1','Recall','Precision','FPR']\nprint(tabulate(df, headers='keys', tablefmt='psql'))\n\n#cm=np.array([TP,FP],[FN,TN])\ncm=confusion_matrix(df_truth['Anom'].values,a2.values)\ncmd=ConfusionMatrixDisplay(cm)\ncmd.plot()\nplt.show()\n```\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"jupyter"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"toc":true,"toc-depth":2,"output-file":"index.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.450","editor":"visual","theme":"cosmo","title-block-banner":true,"title":"Anomaly Detection on Spacecraft Telemetry","author":"Eric Jackson","date":"2023-09-08","categories":["code","analysis"],"image":"image.jpg"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}