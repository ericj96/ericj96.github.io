{
  "hash": "63f22d0b0311747d288f9bbd0b3343b9",
  "result": {
    "markdown": "---\ntitle: \"Anomaly Detection on Spacecraft Telemetry\"\nauthor: \"Eric Jackson\"\ndate: \"2023-09-08\"\ncategories: [code, analysis]\nimage: \"image.jpg\"\ntoc: true\ntoc-depth: 2\n---\n\n# Background\n\nEvery spacecraft that is launched has some form of onboard anomaly responses for most known failure cases in order to safe the vehicle. Normally these are simple low/high limits set for certain monitors (temperature, voltage, etc) with a corresponding response, whether that be a simple visual alarm or powering off certain equipment.\n\nThe problem with anomalies in space is that they can be incredibly hard to predict, as multiple components can react slightly out of family to create a larger issue. Spacecraft will also generate a massive amount of data the longer they are on orbit, and manually looking and trending this data from a human standpoint can miss certain anomalies. But, this large amount of data makes them perfect for utilizing machine learning. Machine learning would allow for these anomalies to not only be identified, but also potentially predicted and prevented, allowing the spacecraft to stay in mission over potentially high priority targets (depending on the payload/mission). An automatic response to a predicted anomaly would limit both downtime and human interaction, as the investigation and implementation can take hours to days before returning to mission.\n\n![Example of anomaly in telemetry data](anomaly.png){width=\"636\"}\n\n# Data Setup & Preprocessing\n\n## Preprocessing\n\nMany spacecraft constellations have decades of on orbit telemetry available, but is mostly proprietary and not available for public use. LASP and NASA releases subsets of data to the public, and this is what was used for this blog post. Reaction wheel temperatures, battery temperatures and voltages, and total bus current datasets were used, each having 750,000+ samples of data over \\~14.5 years. Because ARIMA requires the data to be stationary, each of the datasets is first sampled down to a daily mean which brings the size down to only 5346 data points. This will allow for much faster processing. To increase the number of exogenous features, each dataset is also turned into sets of rolling mean and rolling standard deviation in windows of 3, 7, and 30 days.\n\nUnfold the below code to see the setup of the data and how it is preprocessed as mentioned above.\n\nA visualization of the separation between training and test data can be seen in in @fig-arima2, with the first 75% used for training and the remaining 25% used for test data.\n\n::: {.cell execution_count=1}\n``` {.python .cell-code code-fold=\"true\"}\nimport os\nimport datetime\nfrom math import sqrt\nimport pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot\nfrom statsmodels.tsa.arima_model import ARIMA\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\nfrom statsmodels.tsa.stattools import acf, pacf\nfrom statsmodels.tsa.stattools import adfuller\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nfrom statsmodels.tsa.arima_model import ARIMAResults\nfrom sklearn.metrics import mean_squared_error\nimport sklearn.svm as svm\nimport matplotlib.pyplot as plt\nimport math\nimport warnings\nwarnings.filterwarnings('ignore', '[\\s\\w\\W]*non-unique[\\s\\w\\W]*', DeprecationWarning)\n\ndf=pd.read_csv('./WheelTemperature.csv')\ndf_battemp=pd.read_csv('./BatteryTemperature.csv')\ndf_buscurrent=pd.read_csv('./TotalBusCurrent.csv')\ndf_busvolt=pd.read_csv('./BusVoltage.csv')\n\ndf_battemp.Date = pd.to_datetime(df_battemp.Date, format=\"%m/%d/%Y %H:%M\")\ndf_buscurrent.Date = pd.to_datetime(df_buscurrent.Date, format=\"%m/%d/%Y\")\ndf_busvolt.Date=pd.to_datetime(df_busvolt.Date, format=\"%m/%d/%Y %H:%M\")\ndf.Date = pd.to_datetime(df.Date, format=\"%m/%d/%Y %H:%M\")\n\ndf_battemp=df_battemp.resample('1D',on='Date').mean()\ndf_buscurrent=df_buscurrent.resample('1D',on='Date').mean()\ndf_busvolt=df_busvolt.resample('1D',on='Date').mean()\ndf_busvolt=df_busvolt.loc['2004-02-13':]\ndf=df.resample('1D',on='Date').mean()\n\ndf=pd.concat([df,df_battemp,df_buscurrent,df_busvolt],axis=1)\ndf['Date']=df.index\n\nlag_features = [\"High\", \"Low\", \"Volume\", \"Turnover\", \"NumTrades\"]\nlag_features=[\"High\",\"Temp\",\"Current\",\"Voltage\"]\nwindow1 = 3\nwindow2 = 7\nwindow3 = 30\n\ndf_rolled_3d = df[lag_features].rolling(window=window1, min_periods=0)\ndf_rolled_7d = df[lag_features].rolling(window=window2, min_periods=0)\ndf_rolled_30d = df[lag_features].rolling(window=window3, min_periods=0)\n\ndf_mean_3d = df_rolled_3d.mean().shift(1).reset_index()\ndf_mean_7d = df_rolled_7d.mean().shift(1).reset_index()\ndf_mean_30d = df_rolled_30d.mean().shift(1).reset_index()\n\ndf_std_3d = df_rolled_3d.std().shift(1).reset_index()\ndf_std_7d = df_rolled_7d.std().shift(1).reset_index()\ndf_std_30d = df_rolled_30d.std().shift(1).reset_index()\n\ndf_mean_3d.set_index(\"Date\", drop=True, inplace=True)\ndf_mean_7d.set_index(\"Date\", drop=True, inplace=True)\ndf_mean_30d.set_index(\"Date\", drop=True, inplace=True)\ndf_std_3d.set_index(\"Date\", drop=True, inplace=True)\ndf_std_7d.set_index(\"Date\", drop=True, inplace=True)\ndf_std_30d.set_index(\"Date\", drop=True, inplace=True)\n\nfor feature in lag_features:\n    \n    df[f\"{feature}_mean_lag{window1}\"] = df_mean_3d[feature]\n    df[f\"{feature}_mean_lag{window2}\"] = df_mean_7d[feature]\n    df[f\"{feature}_mean_lag{window3}\"] = df_mean_30d[feature]\n    \n    df[f\"{feature}_std_lag{window1}\"] = df_std_3d[feature]\n    df[f\"{feature}_std_lag{window2}\"] = df_std_7d[feature]\n    df[f\"{feature}_std_lag{window3}\"] = df_std_30d[feature]\n\ndf.Date = pd.to_datetime(df.Date, format=\"%m/%d/%Y %H:%M\")\ndf[\"month\"] = df.Date.dt.month\ndf[\"week\"] = df.Date.dt.isocalendar().week.astype(np.int64)\ndf[\"day\"] = df.Date.dt.day\ndf[\"day_of_week\"] = df.Date.dt.dayofweek\ndf.set_index(\"Date\", drop=True, inplace=True)\ndf.fillna(df.mean(), inplace=True)\n\ndata=df\ndata.index = pd.to_datetime(data.index)\ndata=data.resample('1D').mean()\ndf_train=data.iloc[0:math.floor(len(data)*.75),:]\ndf_valid=data.iloc[math.floor(len(data)*.75):,:]\n\nexogenous_features=['High_mean_lag3', 'High_mean_lag7',\n       'High_mean_lag30', 'High_std_lag3', 'High_std_lag7', 'High_std_lag30',\n       'Temp_mean_lag3', 'Temp_mean_lag7', 'Temp_mean_lag30', 'Temp_std_lag3',\n       'Temp_std_lag7', 'Temp_std_lag30', 'Current_mean_lag3',\n       'Current_mean_lag7', 'Current_mean_lag30', 'Current_std_lag3',\n       'Current_std_lag7', 'Current_std_lag30', 'Voltage_mean_lag3',\n       'Voltage_mean_lag7', 'Voltage_mean_lag30', 'Voltage_std_lag3',\n       'Voltage_std_lag7', 'Voltage_std_lag30', 'month', 'week', 'day',\n       'day_of_week']\n```\n:::\n\n\n::: {.cell execution_count=2}\n\n::: {.cell-output .cell-output-display}\n![Training data is first 75% of wheel temperature data, with the remaining 25% used as the test data for verification](index_files/figure-html/fig-arima2-output-1.png){#fig-arima2 width=808 height=485}\n:::\n:::\n\n\n## Truth Data\n\nIn order to determine the accuracy of the anomaly detection methods used below, a set of truth data points needed to be manually chosen. These points were identified to be points in time where an anomaly took place based on personal experience of operational spacecraft data. 115 out of 1137 total points were marked as anomalous. @fig-truth identifies the anomalies, marked in red.\n\n::: {.cell execution_count=3}\n``` {.python .cell-code code-fold=\"true\"}\ndf_truth=pd.read_csv('./truth.csv')\ndf_truth.Date = pd.to_datetime(df_truth.Date, format=\"%m/%d/%Y\")\ndf_truth.set_index(\"Date\", drop=True, inplace=True)\nanom=df_truth['Anom']\nanom=anom.map(lambda val:1 if val==-1 else 0)\na=df_truth.loc[df_truth['Anom']==1,['High']]\nfig, ax = plt.subplots(figsize=(10,6))\nax.plot(df_truth.index,df_truth['High'], color='black', label = 'ARIMA')\nax.scatter(a.index,a.values, color='red', label = 'Anomaly')\nplt.legend(['Wheel Temperature','Anomaly'])\nplt.ylabel('Temperature (C)')\nplt.title('Truth Anomalies')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![Set of anomalous data points to be used as truth](index_files/figure-html/fig-truth-output-1.png){#fig-truth width=808 height=505}\n:::\n:::\n\n\n# ARIMA Model\n\nThe first step in accurately identifying anomalies with telemetry data is to forecast future data. The ARIMA model is a statistical based model that is specifically made and used for forecasting time series data. Many machine learning algorithms struggle with time series data and are prone to overfitting, so ARIMA is a great option for analyzing spacecraft telemetry data.\n\nARIMA works best with data that is stationary, meaning that most input data will need to be differenced before running the model. This was accomplished in the preprocessing stage above, but the auto_arima function will still perform an Augmented Dickey-Fuller (ADF) test to check for stationary data by looking if a unit root is present in the data.\n\nThere are 3 hyperparameters that are used as input for the auto_arima function (with 3 more parameters if seasonal modeling is desired). These parameters are used to optimize the below equation. Auto_arima will iterate through multiple variations of each parameter to find the best combination with the lowest prediction error (Akaike Information Criteria or AIC).\n\n![Generalized ARIMA model function](https://wikimedia.org/api/rest_v1/media/math/render/svg/b6ebbe31d07e994b209c391e3d6f8f5d88e267c3)\n\nWhere:\n\n-   p = order of auto-regressive model\n\n-   d = order of first-differencing\n\n-   q = order of moving-average model\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\nfrom pmdarima import auto_arima\nfrom sklearn.metrics import mean_absolute_error\n\nmodel = auto_arima(\n\tdf_train[\"High\"],\n\texogenous=df_train[exogenous_features],\n\ttrace=True,\n\terror_action=\"ignore\",\n\tsuppress_warnings=True,\n    seasonal=True,\n    m=1)\nmodel.fit(df_train.High, exogenous=df_train[exogenous_features])\nforecast = model.predict(n_periods=len(df_valid), exogenous=df_valid[exogenous_features])\ndf_valid.insert(len(df_valid.columns),\"Forecast_ARIMAX\",forecast,True)\n\nprint(\"\\nRMSE of Auto ARIMAX:\", np.sqrt(mean_squared_error(df_valid.High, df_valid.Forecast_ARIMAX)))\nprint(\"\\nMAE of Auto ARIMAX:\", mean_absolute_error(df_valid.High, df_valid.Forecast_ARIMAX))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nPerforming stepwise search to minimize aic\n ARIMA(2,0,2)(0,0,0)[0] intercept   : AIC=2960.826, Time=14.72 sec\n ARIMA(0,0,0)(0,0,0)[0] intercept   : AIC=5711.667, Time=1.32 sec\n ARIMA(1,0,0)(0,0,0)[0] intercept   : AIC=3359.247, Time=10.65 sec\n ARIMA(0,0,1)(0,0,0)[0] intercept   : AIC=3726.632, Time=12.84 sec\n ARIMA(0,0,0)(0,0,0)[0]             : AIC=5709.707, Time=13.58 sec\n ARIMA(1,0,2)(0,0,0)[0] intercept   : AIC=2904.191, Time=15.31 sec\n ARIMA(0,0,2)(0,0,0)[0] intercept   : AIC=2912.739, Time=14.14 sec\n ARIMA(1,0,1)(0,0,0)[0] intercept   : AIC=3067.819, Time=13.87 sec\n ARIMA(1,0,3)(0,0,0)[0] intercept   : AIC=2930.144, Time=15.88 sec\n ARIMA(0,0,3)(0,0,0)[0] intercept   : AIC=2936.070, Time=14.93 sec\n ARIMA(2,0,1)(0,0,0)[0] intercept   : AIC=2957.813, Time=12.97 sec\n ARIMA(2,0,3)(0,0,0)[0] intercept   : AIC=2898.815, Time=16.35 sec\n ARIMA(3,0,3)(0,0,0)[0] intercept   : AIC=2805.639, Time=17.36 sec\n ARIMA(3,0,2)(0,0,0)[0] intercept   : AIC=2962.492, Time=15.79 sec\n ARIMA(4,0,3)(0,0,0)[0] intercept   : AIC=2810.038, Time=17.53 sec\n ARIMA(3,0,4)(0,0,0)[0] intercept   : AIC=2785.353, Time=21.42 sec\n ARIMA(2,0,4)(0,0,0)[0] intercept   : AIC=2897.289, Time=18.62 sec\n ARIMA(4,0,4)(0,0,0)[0] intercept   : AIC=2807.535, Time=19.66 sec\n ARIMA(3,0,5)(0,0,0)[0] intercept   : AIC=2789.723, Time=20.88 sec\n ARIMA(2,0,5)(0,0,0)[0] intercept   : AIC=2846.091, Time=20.69 sec\n ARIMA(4,0,5)(0,0,0)[0] intercept   : AIC=2791.733, Time=22.65 sec\n ARIMA(3,0,4)(0,0,0)[0]             : AIC=2809.734, Time=18.21 sec\n\nBest model:  ARIMA(3,0,4)(0,0,0)[0] intercept\nTotal fit time: 349.392 seconds\n\nRMSE of Auto ARIMAX: 0.6141699692631081\n\nMAE of Auto ARIMAX: 0.2635940364491945\n```\n:::\n:::\n\n\nIt can be seen that the auto_arima function performed fairly quickly, finding an optimal model in less than 6 minutes with an RMSE of 0.614 and MAE of 0.263. A visual representation of the ARIMA forecast compared to the actual telemetry data can be seen in @fig-arima\n\n::: {.cell fig-width='30%' execution_count=5}\n\n::: {.cell-output .cell-output-display}\n![Initial ARIMA forecast on reaction wheel temperature data](index_files/figure-html/fig-arima-output-1.png){#fig-arima width=790 height=444}\n:::\n:::\n\n\n# OCSVM\n\nOne class support vector machine algorithm is an unsupervised machine learning method that maps samples of a higher dimensional subspace and finds a hyperplane separating one-class samples from the origin. This splits the data into both positive and negative classes and tries to minimize the volume of training data in the positive class. In the below example, a two dimensional space is seen to be split by a one dimensional hyperplane, with the distance from the origin maximized. Through this process outliers are identified and flagged.\n\nAdvantages:\n\n-   Highly efficient\n\n-   Requires few hyperparameters from the user\n\n-   Eliminated the need for labelled two-class information during training\n\nInputs:\n\n-   nu (upper bound on fraction of errors, used 0.05)\n\n-   kernel (type of function for kernel method, used poly)\n\n[![OCSVM example visualization](https://www.researchgate.net/publication/362912442/figure/fig4/AS:11431281080912015@1661430301368/Schematic-of-the-OCSVM_W640.jpg){width=\"408\"}](https://www.researchgate.net/publication/362912442_Anomaly_Detection_in_Satellite_Telemetry_Data_Using_a_Sparse_Feature-Based_Method/figures?lo=1)\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\n############# OCSVM ##################\n\nfig, ax = plt.subplots(figsize=(10,6))\ndata2=df_valid[\"Forecast_ARIMAX\"]\nmodel =svm.OneClassSVM(nu=0.05,kernel='poly')\nmodel.fit(data2.values.reshape(-1,1))\nanom=(pd.Series(model.predict(data2.values.reshape(-1,1))))\ndf2=pd.DataFrame()\ndf2['Time']=data2.index\ndf2['data']=data2.values\ndf2['anom']=anom\na=df2.loc[df2['anom']==-1,['Time','data']]\ndf2.set_index(\"Time\", drop=True, inplace=True)\nax.plot(df2.index, df2['data'], color='black', label = 'ARIMA')\nax.scatter(a['Time'].values,a['data'], color='red', label = 'Anomaly')\nplt.legend(['Wheel Temperature','Anomaly'])\nplt.ylabel('Temperature (C)')\nplt.title('Anomalies detected with OCSVM')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-7-output-1.png){width=808 height=505}\n:::\n:::\n\n\n# Isolation Forest\n\nIn order to compare OCSVM against something to prove it's worth in anomaly detection, an additional method was chosen. Isolation Forest is a commonly used outlier detection method which detects outliers utilizing binary trees. This method recursively partitions data points based on randomly selected attribute and then assigned anomaly scores based on number of \"splits\" needed to isolate a data point. The training dataset is used to build the \"trees\" and then the validation data is passed through those trees and assigned an anomaly score. Based on the anomaly score, it can be determined which points are outliers.\n\nAdvantages:\n\n-   Low memory utilization\n\n-   Works best with large datasets\n\n![Example of binary trees used to identify outliers via Isolation Forest](https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fcf1c1d99-47bb-4a34-aec5-3431a929335f%2FUntitled.png?table=block&id=79c1ba86-2c87-4f38-8c7f-c496f1763aaf&cache=v2)\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\n######### Isolation Forest ################\nimport sklearn\nfrom sklearn.ensemble import IsolationForest\nisofor=df_valid\noutliers_fraction = float(.01)\nscaler = sklearn.preprocessing.StandardScaler()\nnp_scaled = scaler.fit_transform(isofor['Forecast_ARIMAX'].values.reshape(-1, 1))\ndata = pd.DataFrame(np_scaled)\n# train isolation forest\nmodel =  IsolationForest(contamination=outliers_fraction)\nmodel.fit(data)\n\n\n\nisofor['anomaly'] = model.predict(data)\n# visualization\nfig, ax = plt.subplots(figsize=(10,6))\na = isofor.loc[isofor['anomaly'] == -1, ['Forecast_ARIMAX']] #anomaly\nax.plot(isofor.index, isofor['Forecast_ARIMAX'], color='black', label = 'Normal')\nax.scatter(a.index,a['Forecast_ARIMAX'], color='red', label = 'Anomaly')\nplt.legend(['Wheel Temperature','Anomaly'])\nplt.ylabel('Temperature (C)')\nplt.title('Anomalies detected with Isolation Forest')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-8-output-1.png){width=808 height=505}\n:::\n:::\n\n\n# Final Results\n\nAs seen from the above plots for OCSVM and Isolation Forest, both methods identified anomalous points to some degree of success, but OCSVM identified multiple sections. When comparing to the truth anomalies, and calculating common metrics (F1, recall, precision, and FPR), the below table shows that OCSVM performed multiple times better than Isolation Forest, with similar precision and FPR. The confusion matrices for both OCSVM (@fig-cm1) and Isolation Forest (@fig-cm2) can be seen below.\n\n::: {.cell execution_count=8}\n``` {.python .cell-code code-fold=\"true\"}\n######################### calculate statistics ###########################\nfrom sklearn.metrics import f1_score,recall_score,precision_score\nfrom sklearn.metrics import mean_squared_error\nfrom tabulate import tabulate\nfrom collections import OrderedDict\nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import ConfusionMatrixDisplay\nfrom sklearn.metrics import confusion_matrix\nfrom numpy import array\n\ndef perf_measure(y_actual, y_hat):\n    TP = 0\n    FP = 0\n    TN = 0\n    FN = 0\n\n    for i in range(len(y_hat)): \n        if y_actual[i]==y_hat[i]==1:\n           TP += 1\n        if y_hat[i]==1 and y_actual[i]!=y_hat[i]:\n           FP += 1\n        if y_actual[i]==y_hat[i]==0:\n           TN += 1\n        if y_hat[i]==0 and y_actual[i]!=y_hat[i]:\n           FN += 1\n\n    return(TP, FP, TN, FN)\n```\n:::\n\n\n::: {.cell execution_count=9}\n``` {.python .cell-code code-fold=\"true\"}\ndf_truth=pd.read_csv('./truth.csv')\nanom=anom.map(lambda val:1 if val==-1 else 0)\n#calculate F1 score\nf1=f1_score(df_truth['Anom'].values, anom.values)\nrec=recall_score(df_truth['Anom'].values, anom.values)\nprec=precision_score(df_truth['Anom'].values, anom.values)\nTP, FP, TN, FN=perf_measure(df_truth['Anom'].values, anom.values)\nfpr=FP/(TN+FP)\nfinal=OrderedDict()\nfinal['OCSVM']=[f1,rec,prec,fpr]\n\na2=isofor['anomaly']\na2=a2.map(lambda val:1 if val==-1 else 0)\nf1=f1_score(df_truth['Anom'].values, a2.values)\nrec=recall_score(df_truth['Anom'].values, a2.values)\nprec=precision_score(df_truth['Anom'].values, a2.values)\nTP, FP, TN, FN=perf_measure(df_truth['Anom'].values, a2.values)\nfpr=FP/(TN+FP)\nfinal['IsoFor']=[f1,rec,prec,fpr]\ndf=pd.DataFrame(final)\ndf.index=['F1','Recall','Precision','FPR']\nprint(tabulate(df, headers='keys', tablefmt='psql'))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n+-----------+-------------+----------+\n|           |       OCSVM |   IsoFor |\n|-----------+-------------+----------|\n| F1        | 0.718232    | 0.217054 |\n| Recall    | 0.565217    | 0.121739 |\n| Precision | 0.984848    | 1        |\n| FPR       | 0.000818331 | 0        |\n+-----------+-------------+----------+\n```\n:::\n:::\n\n\n::: {.cell fig-width='30%' execution_count=10}\n\n::: {.cell-output .cell-output-display}\n![Confusion matrix for OCSVM method](index_files/figure-html/fig-cm1-output-1.png){#fig-cm1 width=513 height=429}\n:::\n:::\n\n\n::: {.cell fig-width='30%' execution_count=11}\n\n::: {.cell-output .cell-output-display}\n![Confusion matrix for Isolation Forest method](index_files/figure-html/fig-cm2-output-1.png){#fig-cm2 width=513 height=429}\n:::\n:::\n\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}