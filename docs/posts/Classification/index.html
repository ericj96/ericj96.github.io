<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Eric Jackson">
<meta name="dcterms.date" content="2023-10-04">

<title>Fall 2023 CS 5805 Blog - Classification Methods</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Fall 2023 CS 5805 Blog</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html" rel="" target="">
 <span class="menu-text">About: Eric Jackson</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/ericj96" rel="" target=""><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <div class="quarto-title-block"><div><h1 class="title">Classification Methods</h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">View Source</a></li></ul></div></div>
                                <div class="quarto-categories">
                <div class="quarto-category">classification</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Eric Jackson </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">October 4, 2023</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul class="collapse">
  <li><a href="#background-and-setup" id="toc-background-and-setup" class="nav-link active" data-scroll-target="#background-and-setup">Background and Setup</a></li>
  <li><a href="#classification-algorithms" id="toc-classification-algorithms" class="nav-link" data-scroll-target="#classification-algorithms">Classification Algorithms</a>
  <ul class="collapse">
  <li><a href="#gaussian-naive-bayes" id="toc-gaussian-naive-bayes" class="nav-link" data-scroll-target="#gaussian-naive-bayes">Gaussian Naive Bayes</a></li>
  <li><a href="#gaussian-process-classification" id="toc-gaussian-process-classification" class="nav-link" data-scroll-target="#gaussian-process-classification">Gaussian Process Classification</a></li>
  <li><a href="#random-forest-classifier" id="toc-random-forest-classifier" class="nav-link" data-scroll-target="#random-forest-classifier">Random Forest Classifier</a></li>
  </ul></li>
  <li><a href="#results-and-conclusion" id="toc-results-and-conclusion" class="nav-link" data-scroll-target="#results-and-conclusion">Results and Conclusion</a></li>
  </ul>
<div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/ericj96/ericj96.github.io/blob/main/posts/Classification/index.qmd" class="toc-action">View source</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<section id="background-and-setup" class="level1">
<h1>Background and Setup</h1>
<p>Classification is similar to clustering (<a href="https://ericj96.github.io/posts/Clustering/">as mentioned in this blog post</a>) in the sense that they group data together into separate categories. The difference comes from the fact that classification has a predefined set of labels that are attached to each data point, and in clustering the labels are missing and the algorithm will apply those labels/groupings. These two topics are commonly referenced as supervised and unsupervised learning (classification vs clustering).</p>
<p>Some of the downsides of classification are that there is a need to train the model before using it with test data, whereas clustering does not require such training and can group data points together immediately. But, classification can be used for much more intensive scenarios, such as handwriting recognition and spam filtering.</p>
<p>As mentioned before, classification algorithms or models require inputs with labels predefined. For this blog post, a native sklearn dataset containing measurements of a species of flower will be used. As seen below, there are width and length measurements along with the label/target class for the species of flower.</p>
<div class="cell" data-execution_count="1">
<details>
<summary>Setup/imports</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>warnings.filterwarnings(<span class="st">'ignore'</span>)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> classification_report, confusion_matrix</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> load_iris</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.naive_bayes <span class="im">import</span> GaussianNB</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.gaussian_process <span class="im">import</span> GaussianProcessClassifier</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.pipeline <span class="im">import</span> make_pipeline</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> ConfusionMatrixDisplay</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.inspection <span class="im">import</span> DecisionBoundaryDisplay</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>iris<span class="op">=</span>load_iris()</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame(iris[<span class="st">'data'</span>],columns <span class="op">=</span> iris[<span class="st">'feature_names'</span>])</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>target<span class="op">=</span>pd.DataFrame(iris[<span class="st">'target'</span>])</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>target[target<span class="op">==</span><span class="dv">0</span>]<span class="op">=</span>iris.target_names[<span class="dv">0</span>]</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>target[target<span class="op">==</span><span class="dv">1</span>]<span class="op">=</span>iris.target_names[<span class="dv">1</span>]</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>target[target<span class="op">==</span><span class="dv">2</span>]<span class="op">=</span>iris.target_names[<span class="dv">2</span>]</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'target'</span>]<span class="op">=</span>target</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="co"># breaking up data into training and test datasets</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>x_train<span class="op">=</span>df[[<span class="st">'petal length (cm)'</span>, <span class="st">'petal width (cm)'</span>]]</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>y_train<span class="op">=</span>df[<span class="st">'target'</span>]</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>x_test<span class="op">=</span>df[[<span class="st">'petal length (cm)'</span>, <span class="st">'petal width (cm)'</span>]]</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>y_test<span class="op">=</span>df[<span class="st">'target'</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="3">
<div class="cell-output cell-output-display" data-execution_count="3">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">sepal length (cm)</th>
<th data-quarto-table-cell-role="th">sepal width (cm)</th>
<th data-quarto-table-cell-role="th">petal length (cm)</th>
<th data-quarto-table-cell-role="th">petal width (cm)</th>
<th data-quarto-table-cell-role="th">target</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>5.1</td>
<td>3.5</td>
<td>1.4</td>
<td>0.2</td>
<td>setosa</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>4.9</td>
<td>3.0</td>
<td>1.4</td>
<td>0.2</td>
<td>setosa</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>4.7</td>
<td>3.2</td>
<td>1.3</td>
<td>0.2</td>
<td>setosa</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>4.6</td>
<td>3.1</td>
<td>1.5</td>
<td>0.2</td>
<td>setosa</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>5.0</td>
<td>3.6</td>
<td>1.4</td>
<td>0.2</td>
<td>setosa</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">145</td>
<td>6.7</td>
<td>3.0</td>
<td>5.2</td>
<td>2.3</td>
<td>virginica</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">146</td>
<td>6.3</td>
<td>2.5</td>
<td>5.0</td>
<td>1.9</td>
<td>virginica</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">147</td>
<td>6.5</td>
<td>3.0</td>
<td>5.2</td>
<td>2.0</td>
<td>virginica</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">148</td>
<td>6.2</td>
<td>3.4</td>
<td>5.4</td>
<td>2.3</td>
<td>virginica</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">149</td>
<td>5.9</td>
<td>3.0</td>
<td>5.1</td>
<td>1.8</td>
<td>virginica</td>
</tr>
</tbody>
</table>

<p>150 rows × 5 columns</p>
</div>
</div>
</div>
<p>Before the data is to be run through any classification algorithms, it is helpful to first plot the data and review what to expect. <a href="#fig-class">Figure&nbsp;1</a> shows the dataset visually with each color representing a different label or species of flower.</p>
<div class="cell" data-execution_count="4">
<details>
<summary>Plotting code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>fig, axs <span class="op">=</span> plt.subplots(figsize <span class="op">=</span>(<span class="dv">7</span>, <span class="dv">5</span>))</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>plt.scatter(df[<span class="st">'petal length (cm)'</span>][df[<span class="st">'target'</span>]<span class="op">==</span>iris.target_names[<span class="dv">0</span>]],df[<span class="st">'petal width (cm)'</span>][df[<span class="st">'target'</span>]<span class="op">==</span>iris.target_names[<span class="dv">0</span>]])</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>plt.scatter(df[<span class="st">'petal length (cm)'</span>][df[<span class="st">'target'</span>]<span class="op">==</span>iris.target_names[<span class="dv">1</span>]],df[<span class="st">'petal width (cm)'</span>][df[<span class="st">'target'</span>]<span class="op">==</span>iris.target_names[<span class="dv">1</span>]])</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>plt.scatter(df[<span class="st">'petal length (cm)'</span>][df[<span class="st">'target'</span>]<span class="op">==</span>iris.target_names[<span class="dv">2</span>]],df[<span class="st">'petal width (cm)'</span>][df[<span class="st">'target'</span>]<span class="op">==</span>iris.target_names[<span class="dv">2</span>]])</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'petal length (cm)'</span>)</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'petal width (cm)'</span>)</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>plt.legend(iris.target_names)</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="fig-class" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="index_files/figure-html/fig-class-output-1.png" width="589" height="429" class="figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;1: Dataset values broken into their defined target labels</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="classification-algorithms" class="level1">
<h1>Classification Algorithms</h1>
<section id="gaussian-naive-bayes" class="level2">
<h2 class="anchored" data-anchor-id="gaussian-naive-bayes">Gaussian Naive Bayes</h2>
<p>The Gaussian Naive Bayes algorithm from the sklearn library (<a href="https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html">see here</a>) utilizes Bayes’ theorem assuming the features probability is distributed in a Gaussian or normal fashion, with the variance and mean of each data point calculated for each class. There are a multitude of Naive Bayes classifier algorithms (Bernoulli, Multinomial, etc), but the specific Gaussian probabilistic version used here is especially useful when the values are continuous and expected to follow a Gaussian distribution.</p>
<p>As seen from <a href="#fig-nb">Figure&nbsp;2</a>, the algorithm uses circular decision boundaries to classify each set of labels. The confusion matrix on the right shows that out of 150 samples, it only incorrectly labeled 6 points leading to a mean accuracy of 96%.</p>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>nb <span class="op">=</span> GaussianNB()</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>nb.fit(x_train, y_train)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Mean accuracy score: </span><span class="sc">%3.3f%%</span><span class="st">'</span> <span class="op">%</span> (nb.score(x_test,y_test)<span class="op">*</span><span class="dv">100</span>))</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>y_pred<span class="op">=</span>nb.predict(x_train)</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>cm<span class="op">=</span>confusion_matrix(y_train,y_pred,labels<span class="op">=</span>iris.target_names)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Mean accuracy score: 96.000%</code></pre>
</div>
</div>
<div class="cell" data-execution_count="6">
<details>
<summary>Plotting code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># decision boundary code adapted from https://hackernoon.com/how-to-plot-a-decision-boundary-for-machine-learning-algorithms-in-python-3o1n3w07</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>fig, axs <span class="op">=</span> plt.subplots(<span class="dv">1</span>,<span class="dv">2</span>,figsize <span class="op">=</span>(<span class="dv">8</span>, <span class="dv">5</span>))</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">121</span>)</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>x1grid <span class="op">=</span> np.linspace(x_train[<span class="st">'petal length (cm)'</span>].<span class="bu">min</span>()<span class="op">-</span><span class="fl">.2</span>, x_train[<span class="st">'petal length (cm)'</span>].<span class="bu">max</span>()<span class="op">+</span><span class="fl">.2</span>, <span class="bu">len</span>(x_train))</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>x2grid <span class="op">=</span> np.linspace(x_train[<span class="st">'petal width (cm)'</span>].<span class="bu">min</span>()<span class="op">-</span><span class="fl">.2</span>, x_train[<span class="st">'petal width (cm)'</span>].<span class="bu">max</span>()<span class="op">+</span><span class="fl">.2</span>, <span class="bu">len</span>(x_train))</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>xx, yy <span class="op">=</span> np.meshgrid(x1grid, x2grid)</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>r1, r2 <span class="op">=</span> xx.flatten(), yy.flatten()</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>r1, r2 <span class="op">=</span> r1.reshape((<span class="bu">len</span>(r1), <span class="dv">1</span>)), r2.reshape((<span class="bu">len</span>(r2), <span class="dv">1</span>))</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>grid <span class="op">=</span> np.hstack((r1,r2))</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>y_pred_grid<span class="op">=</span>nb.predict(grid)</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>zz <span class="op">=</span> y_pred_grid.reshape(xx.shape)</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>zz[zz<span class="op">==</span><span class="st">'setosa'</span>]<span class="op">=</span><span class="dv">1</span></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>zz[zz<span class="op">==</span><span class="st">'versicolor'</span>]<span class="op">=</span><span class="dv">2</span></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>zz[zz<span class="op">==</span><span class="st">'virginica'</span>]<span class="op">=</span><span class="dv">3</span></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>xx<span class="op">=</span>np.array(xx,dtype<span class="op">=</span><span class="bu">float</span>)</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>yy<span class="op">=</span>np.array(yy,dtype<span class="op">=</span><span class="bu">float</span>)</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>zz<span class="op">=</span>np.array(zz,dtype<span class="op">=</span><span class="bu">float</span>)</span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>plt.scatter(x_train[<span class="st">'petal length (cm)'</span>][y_pred<span class="op">==</span>iris.target_names[<span class="dv">0</span>]],x_train[<span class="st">'petal width (cm)'</span>][y_pred<span class="op">==</span>iris.target_names[<span class="dv">0</span>]],zorder<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>plt.scatter(x_train[<span class="st">'petal length (cm)'</span>][y_pred<span class="op">==</span>iris.target_names[<span class="dv">1</span>]],x_train[<span class="st">'petal width (cm)'</span>][y_pred<span class="op">==</span>iris.target_names[<span class="dv">1</span>]],zorder<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>plt.scatter(x_train[<span class="st">'petal length (cm)'</span>][y_pred<span class="op">==</span>iris.target_names[<span class="dv">2</span>]],x_train[<span class="st">'petal width (cm)'</span>][y_pred<span class="op">==</span>iris.target_names[<span class="dv">2</span>]],zorder<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'petal length (cm)'</span>)</span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'petal width (cm)'</span>)</span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a>plt.legend(iris.target_names)</span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a>plt.contourf(xx, yy, zz,cmap<span class="op">=</span><span class="st">'RdBu_r'</span>)</span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">122</span>)</span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a>ConfusionMatrixDisplay.from_predictions(y_train,y_pred,ax<span class="op">=</span>axs[<span class="dv">1</span>],colorbar<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()  </span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="fig-nb" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="index_files/figure-html/fig-nb-output-1.png" width="757" height="468" class="figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;2: Gaussian Naive Bayes classification results (with decision boundaries) and confusion matrix</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="gaussian-process-classification" class="level2">
<h2 class="anchored" data-anchor-id="gaussian-process-classification">Gaussian Process Classification</h2>
<p>The Gaussian Process Classification algorithm from the sklearn library (<a href="https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.GaussianProcessClassifier.html">see here</a>) uses a general form of the Gaussian probability distribution model and is based on Laplace approximation. As it uses Gaussian probability, the model can compute confidence intervals and determine if refitting of a certain section is required based on probability alone. The algorithm is kernel based, meaning multiple types of covariance functions can be utilized and used to optimize model fitting based on the input data. One downside of this algorithm is that is loses efficiency when the number of features grows larger than a few dozen.</p>
<p>As seen from <a href="#fig-gmm">Figure&nbsp;3</a>, the algorithm uses more linear decision boundaries compared to the above Gaussian Naive to classify each set of labels. The confusion matrix on the right shows that out of 150 samples, it only incorrectly labeled 5 points leading to a mean accuracy of 96.667%. Both of these algorithms are Gaussian in nature, so it is expected that they have similar results.</p>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>nb <span class="op">=</span> GaussianProcessClassifier()</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>nb.fit(x_train, y_train)</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Mean accuracy score: </span><span class="sc">%3.3f%%</span><span class="st">'</span> <span class="op">%</span> (nb.score(x_test,y_test)<span class="op">*</span><span class="dv">100</span>))</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>y_pred<span class="op">=</span>nb.predict(x_train)</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>cm<span class="op">=</span>confusion_matrix(y_train,y_pred,labels<span class="op">=</span>iris.target_names)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Mean accuracy score: 96.667%</code></pre>
</div>
</div>
<div class="cell" data-execution_count="8">
<details>
<summary>Plotting code</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># decision boundary code adapted from https://hackernoon.com/how-to-plot-a-decision-boundary-for-machine-learning-algorithms-in-python-3o1n3w07</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>fig, axs <span class="op">=</span> plt.subplots(<span class="dv">1</span>,<span class="dv">2</span>,figsize <span class="op">=</span>(<span class="dv">8</span>, <span class="dv">5</span>))</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">121</span>)</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>x1grid <span class="op">=</span> np.linspace(x_train[<span class="st">'petal length (cm)'</span>].<span class="bu">min</span>()<span class="op">-</span><span class="fl">.2</span>, x_train[<span class="st">'petal length (cm)'</span>].<span class="bu">max</span>()<span class="op">+</span><span class="fl">.2</span>, <span class="bu">len</span>(x_train))</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>x2grid <span class="op">=</span> np.linspace(x_train[<span class="st">'petal width (cm)'</span>].<span class="bu">min</span>()<span class="op">-</span><span class="fl">.2</span>, x_train[<span class="st">'petal width (cm)'</span>].<span class="bu">max</span>()<span class="op">+</span><span class="fl">.2</span>, <span class="bu">len</span>(x_train))</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>xx, yy <span class="op">=</span> np.meshgrid(x1grid, x2grid)</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>r1, r2 <span class="op">=</span> xx.flatten(), yy.flatten()</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>r1, r2 <span class="op">=</span> r1.reshape((<span class="bu">len</span>(r1), <span class="dv">1</span>)), r2.reshape((<span class="bu">len</span>(r2), <span class="dv">1</span>))</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>grid <span class="op">=</span> np.hstack((r1,r2))</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>y_pred_grid<span class="op">=</span>nb.predict(grid)</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>zz <span class="op">=</span> y_pred_grid.reshape(xx.shape)</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>zz[zz<span class="op">==</span><span class="st">'setosa'</span>]<span class="op">=</span><span class="dv">1</span></span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>zz[zz<span class="op">==</span><span class="st">'versicolor'</span>]<span class="op">=</span><span class="dv">2</span></span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>zz[zz<span class="op">==</span><span class="st">'virginica'</span>]<span class="op">=</span><span class="dv">3</span></span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>xx<span class="op">=</span>np.array(xx,dtype<span class="op">=</span><span class="bu">float</span>)</span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>yy<span class="op">=</span>np.array(yy,dtype<span class="op">=</span><span class="bu">float</span>)</span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>zz<span class="op">=</span>np.array(zz,dtype<span class="op">=</span><span class="bu">float</span>)</span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a>plt.scatter(x_train[<span class="st">'petal length (cm)'</span>][y_pred<span class="op">==</span>iris.target_names[<span class="dv">0</span>]],x_train[<span class="st">'petal width (cm)'</span>][y_pred<span class="op">==</span>iris.target_names[<span class="dv">0</span>]],zorder<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a>plt.scatter(x_train[<span class="st">'petal length (cm)'</span>][y_pred<span class="op">==</span>iris.target_names[<span class="dv">1</span>]],x_train[<span class="st">'petal width (cm)'</span>][y_pred<span class="op">==</span>iris.target_names[<span class="dv">1</span>]],zorder<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a>plt.scatter(x_train[<span class="st">'petal length (cm)'</span>][y_pred<span class="op">==</span>iris.target_names[<span class="dv">2</span>]],x_train[<span class="st">'petal width (cm)'</span>][y_pred<span class="op">==</span>iris.target_names[<span class="dv">2</span>]],zorder<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'petal length (cm)'</span>)</span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'petal width (cm)'</span>)</span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a>plt.legend(iris.target_names)</span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a>plt.contourf(xx, yy, zz,cmap<span class="op">=</span><span class="st">'RdBu_r'</span>)</span>
<span id="cb9-25"><a href="#cb9-25" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">122</span>)</span>
<span id="cb9-26"><a href="#cb9-26" aria-hidden="true" tabindex="-1"></a>ConfusionMatrixDisplay.from_predictions(y_train,y_pred,ax<span class="op">=</span>axs[<span class="dv">1</span>],colorbar<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb9-27"><a href="#cb9-27" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()  </span>
<span id="cb9-28"><a href="#cb9-28" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="fig-gmm" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="index_files/figure-html/fig-gmm-output-1.png" width="757" height="468" class="figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;3: Gaussian Process Classifier classification results (with decision boundaries) and confusion matrix</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="random-forest-classifier" class="level2">
<h2 class="anchored" data-anchor-id="random-forest-classifier">Random Forest Classifier</h2>
<p>The Random Forest Classifier as part of the sklearn library (<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html">see here</a>) uses decision tree classifiers on multiple parts of the dataset, and then averages scores from each one to maintain a high accuracy and attempt to prevent over fitting. The default arguments were used for this algorithm, but the most important one to call out and be aware of is the number of trees/estimators in the forest is defaulted to 100. Random Forest has the additional benefit of being less computationally expensive as other classification models, such as neural networks.</p>
<p>As seen from <a href="#fig-rf">Figure&nbsp;4</a>, the algorithm uses boxier decision boundaries than the previous two algorithms to classify each set of labels. The confusion matrix on the right shows that out of 150 samples, it only incorrectly labeled 1 point leading to a mean accuracy of 99.333%. This is by far the best accuracy score of the three algorithms and would be the best model to use for this specific dataset for further work.</p>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>nb <span class="op">=</span> RandomForestClassifier()</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>nb.fit(x_train, y_train)</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Mean accuracy score: </span><span class="sc">%3.3f%%</span><span class="st">'</span> <span class="op">%</span> (nb.score(x_test,y_test)<span class="op">*</span><span class="dv">100</span>))</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>y_pred<span class="op">=</span>nb.predict(x_train)</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>cm<span class="op">=</span>confusion_matrix(y_train,y_pred,labels<span class="op">=</span>iris.target_names)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Mean accuracy score: 99.333%</code></pre>
</div>
</div>
<div class="cell" data-execution_count="10">
<details>
<summary>Plotting code</summary>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># decision boundary code adapted from https://hackernoon.com/how-to-plot-a-decision-boundary-for-machine-learning-algorithms-in-python-3o1n3w07</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>fig, axs <span class="op">=</span> plt.subplots(<span class="dv">1</span>,<span class="dv">2</span>,figsize <span class="op">=</span>(<span class="dv">8</span>, <span class="dv">5</span>))</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">121</span>)</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>x1grid <span class="op">=</span> np.linspace(x_train[<span class="st">'petal length (cm)'</span>].<span class="bu">min</span>()<span class="op">-</span><span class="fl">.2</span>, x_train[<span class="st">'petal length (cm)'</span>].<span class="bu">max</span>()<span class="op">+</span><span class="fl">.2</span>, <span class="bu">len</span>(x_train))</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>x2grid <span class="op">=</span> np.linspace(x_train[<span class="st">'petal width (cm)'</span>].<span class="bu">min</span>()<span class="op">-</span><span class="fl">.2</span>, x_train[<span class="st">'petal width (cm)'</span>].<span class="bu">max</span>()<span class="op">+</span><span class="fl">.2</span>, <span class="bu">len</span>(x_train))</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>xx, yy <span class="op">=</span> np.meshgrid(x1grid, x2grid)</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>r1, r2 <span class="op">=</span> xx.flatten(), yy.flatten()</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>r1, r2 <span class="op">=</span> r1.reshape((<span class="bu">len</span>(r1), <span class="dv">1</span>)), r2.reshape((<span class="bu">len</span>(r2), <span class="dv">1</span>))</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>grid <span class="op">=</span> np.hstack((r1,r2))</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>y_pred_grid<span class="op">=</span>nb.predict(grid)</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>zz <span class="op">=</span> y_pred_grid.reshape(xx.shape)</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>zz[zz<span class="op">==</span><span class="st">'setosa'</span>]<span class="op">=</span><span class="dv">1</span></span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>zz[zz<span class="op">==</span><span class="st">'versicolor'</span>]<span class="op">=</span><span class="dv">2</span></span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>zz[zz<span class="op">==</span><span class="st">'virginica'</span>]<span class="op">=</span><span class="dv">3</span></span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>xx<span class="op">=</span>np.array(xx,dtype<span class="op">=</span><span class="bu">float</span>)</span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>yy<span class="op">=</span>np.array(yy,dtype<span class="op">=</span><span class="bu">float</span>)</span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>zz<span class="op">=</span>np.array(zz,dtype<span class="op">=</span><span class="bu">float</span>)</span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a>plt.scatter(x_train[<span class="st">'petal length (cm)'</span>][y_pred<span class="op">==</span>iris.target_names[<span class="dv">0</span>]],x_train[<span class="st">'petal width (cm)'</span>][y_pred<span class="op">==</span>iris.target_names[<span class="dv">0</span>]],zorder<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a>plt.scatter(x_train[<span class="st">'petal length (cm)'</span>][y_pred<span class="op">==</span>iris.target_names[<span class="dv">1</span>]],x_train[<span class="st">'petal width (cm)'</span>][y_pred<span class="op">==</span>iris.target_names[<span class="dv">1</span>]],zorder<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a>plt.scatter(x_train[<span class="st">'petal length (cm)'</span>][y_pred<span class="op">==</span>iris.target_names[<span class="dv">2</span>]],x_train[<span class="st">'petal width (cm)'</span>][y_pred<span class="op">==</span>iris.target_names[<span class="dv">2</span>]],zorder<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'petal length (cm)'</span>)</span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'petal width (cm)'</span>)</span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a>plt.legend(iris.target_names)</span>
<span id="cb12-24"><a href="#cb12-24" aria-hidden="true" tabindex="-1"></a>plt.contourf(xx, yy, zz,cmap<span class="op">=</span><span class="st">'RdBu_r'</span>)</span>
<span id="cb12-25"><a href="#cb12-25" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">122</span>)</span>
<span id="cb12-26"><a href="#cb12-26" aria-hidden="true" tabindex="-1"></a>ConfusionMatrixDisplay.from_predictions(y_train,y_pred,ax<span class="op">=</span>axs[<span class="dv">1</span>],colorbar<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb12-27"><a href="#cb12-27" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()  </span>
<span id="cb12-28"><a href="#cb12-28" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="fig-rf" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="index_files/figure-html/fig-rf-output-1.png" width="757" height="468" class="figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;4: Random Forest Classifier classification results (with decision boundaries) and confusion matrix</figcaption>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="results-and-conclusion" class="level1">
<h1>Results and Conclusion</h1>
<p>The three classification algorithms used in this blog post used a relatively small dataset to attempt and match the original labels. Both Gaussian classification models (Gaussian Naive Bayes and Gaussian Process Classification) performed similarly and had ~96% accuracy. The Random Forest classification algorithm performed much better than the previous two, with a mean accuracy score &gt; 99% and only misidentified a single data point.</p>


<!-- -->

</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb13" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Classification Methods"</span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="an">author:</span><span class="co"> "Eric Jackson"</span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="an">date:</span><span class="co"> "2023-10-04"</span></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="an">categories:</span><span class="co"> [classification]</span></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a><span class="an">image:</span><span class="co"> "image.jpg"</span></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a><span class="an">toc:</span><span class="co"> true</span></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a><span class="an">toc-depth:</span><span class="co"> 2</span></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a><span class="fu"># Background and Setup</span></span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>Classification is similar to clustering (<span class="co">[</span><span class="ot">as mentioned in this blog post</span><span class="co">](https://ericj96.github.io/posts/Clustering/)</span>) in the sense that they group data together into separate categories. The difference comes from the fact that classification has a predefined set of labels that are attached to each data point, and in clustering the labels are missing and the algorithm will apply those labels/groupings. These two topics are commonly referenced as supervised and unsupervised learning (classification vs clustering).</span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>Some of the downsides of classification are that there is a need to train the model before using it with test data, whereas clustering does not require such training and can group data points together immediately. But, classification can be used for much more intensive scenarios, such as handwriting recognition and spam filtering.</span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>As mentioned before, classification algorithms or models require inputs with labels predefined. For this blog post, a native sklearn dataset containing measurements of a species of flower will be used. As seen below, there are width and length measurements along with the label/target class for the species of flower.</span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: Setup/imports</span></span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings</span>
<span id="cb13-26"><a href="#cb13-26" aria-hidden="true" tabindex="-1"></a>warnings.filterwarnings(<span class="st">'ignore'</span>)</span>
<span id="cb13-27"><a href="#cb13-27" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb13-28"><a href="#cb13-28" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb13-29"><a href="#cb13-29" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb13-30"><a href="#cb13-30" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> classification_report, confusion_matrix</span>
<span id="cb13-31"><a href="#cb13-31" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> load_iris</span>
<span id="cb13-32"><a href="#cb13-32" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.naive_bayes <span class="im">import</span> GaussianNB</span>
<span id="cb13-33"><a href="#cb13-33" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.gaussian_process <span class="im">import</span> GaussianProcessClassifier</span>
<span id="cb13-34"><a href="#cb13-34" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier</span>
<span id="cb13-35"><a href="#cb13-35" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.pipeline <span class="im">import</span> make_pipeline</span>
<span id="cb13-36"><a href="#cb13-36" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> ConfusionMatrixDisplay</span>
<span id="cb13-37"><a href="#cb13-37" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.inspection <span class="im">import</span> DecisionBoundaryDisplay</span>
<span id="cb13-38"><a href="#cb13-38" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb13-39"><a href="#cb13-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-42"><a href="#cb13-42" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb13-43"><a href="#cb13-43" aria-hidden="true" tabindex="-1"></a>iris<span class="op">=</span>load_iris()</span>
<span id="cb13-44"><a href="#cb13-44" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame(iris[<span class="st">'data'</span>],columns <span class="op">=</span> iris[<span class="st">'feature_names'</span>])</span>
<span id="cb13-45"><a href="#cb13-45" aria-hidden="true" tabindex="-1"></a>target<span class="op">=</span>pd.DataFrame(iris[<span class="st">'target'</span>])</span>
<span id="cb13-46"><a href="#cb13-46" aria-hidden="true" tabindex="-1"></a>target[target<span class="op">==</span><span class="dv">0</span>]<span class="op">=</span>iris.target_names[<span class="dv">0</span>]</span>
<span id="cb13-47"><a href="#cb13-47" aria-hidden="true" tabindex="-1"></a>target[target<span class="op">==</span><span class="dv">1</span>]<span class="op">=</span>iris.target_names[<span class="dv">1</span>]</span>
<span id="cb13-48"><a href="#cb13-48" aria-hidden="true" tabindex="-1"></a>target[target<span class="op">==</span><span class="dv">2</span>]<span class="op">=</span>iris.target_names[<span class="dv">2</span>]</span>
<span id="cb13-49"><a href="#cb13-49" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'target'</span>]<span class="op">=</span>target</span>
<span id="cb13-50"><a href="#cb13-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-51"><a href="#cb13-51" aria-hidden="true" tabindex="-1"></a><span class="co"># breaking up data into training and test datasets</span></span>
<span id="cb13-52"><a href="#cb13-52" aria-hidden="true" tabindex="-1"></a>x_train<span class="op">=</span>df[[<span class="st">'petal length (cm)'</span>, <span class="st">'petal width (cm)'</span>]]</span>
<span id="cb13-53"><a href="#cb13-53" aria-hidden="true" tabindex="-1"></a>y_train<span class="op">=</span>df[<span class="st">'target'</span>]</span>
<span id="cb13-54"><a href="#cb13-54" aria-hidden="true" tabindex="-1"></a>x_test<span class="op">=</span>df[[<span class="st">'petal length (cm)'</span>, <span class="st">'petal width (cm)'</span>]]</span>
<span id="cb13-55"><a href="#cb13-55" aria-hidden="true" tabindex="-1"></a>y_test<span class="op">=</span>df[<span class="st">'target'</span>]</span>
<span id="cb13-56"><a href="#cb13-56" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb13-57"><a href="#cb13-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-60"><a href="#cb13-60" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb13-61"><a href="#cb13-61" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb13-62"><a href="#cb13-62" aria-hidden="true" tabindex="-1"></a>df</span>
<span id="cb13-63"><a href="#cb13-63" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb13-64"><a href="#cb13-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-65"><a href="#cb13-65" aria-hidden="true" tabindex="-1"></a>Before the data is to be run through any classification algorithms, it is helpful to first plot the data and review what to expect. @fig-class shows the dataset visually with each color representing a different label or species of flower.</span>
<span id="cb13-66"><a href="#cb13-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-69"><a href="#cb13-69" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb13-70"><a href="#cb13-70" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb13-71"><a href="#cb13-71" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: Plotting code</span></span>
<span id="cb13-72"><a href="#cb13-72" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: Dataset values broken into their defined target labels</span></span>
<span id="cb13-73"><a href="#cb13-73" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-class</span></span>
<span id="cb13-74"><a href="#cb13-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-75"><a href="#cb13-75" aria-hidden="true" tabindex="-1"></a>fig, axs <span class="op">=</span> plt.subplots(figsize <span class="op">=</span>(<span class="dv">7</span>, <span class="dv">5</span>))</span>
<span id="cb13-76"><a href="#cb13-76" aria-hidden="true" tabindex="-1"></a>plt.scatter(df[<span class="st">'petal length (cm)'</span>][df[<span class="st">'target'</span>]<span class="op">==</span>iris.target_names[<span class="dv">0</span>]],df[<span class="st">'petal width (cm)'</span>][df[<span class="st">'target'</span>]<span class="op">==</span>iris.target_names[<span class="dv">0</span>]])</span>
<span id="cb13-77"><a href="#cb13-77" aria-hidden="true" tabindex="-1"></a>plt.scatter(df[<span class="st">'petal length (cm)'</span>][df[<span class="st">'target'</span>]<span class="op">==</span>iris.target_names[<span class="dv">1</span>]],df[<span class="st">'petal width (cm)'</span>][df[<span class="st">'target'</span>]<span class="op">==</span>iris.target_names[<span class="dv">1</span>]])</span>
<span id="cb13-78"><a href="#cb13-78" aria-hidden="true" tabindex="-1"></a>plt.scatter(df[<span class="st">'petal length (cm)'</span>][df[<span class="st">'target'</span>]<span class="op">==</span>iris.target_names[<span class="dv">2</span>]],df[<span class="st">'petal width (cm)'</span>][df[<span class="st">'target'</span>]<span class="op">==</span>iris.target_names[<span class="dv">2</span>]])</span>
<span id="cb13-79"><a href="#cb13-79" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'petal length (cm)'</span>)</span>
<span id="cb13-80"><a href="#cb13-80" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'petal width (cm)'</span>)</span>
<span id="cb13-81"><a href="#cb13-81" aria-hidden="true" tabindex="-1"></a>plt.legend(iris.target_names)</span>
<span id="cb13-82"><a href="#cb13-82" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb13-83"><a href="#cb13-83" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb13-84"><a href="#cb13-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-85"><a href="#cb13-85" aria-hidden="true" tabindex="-1"></a><span class="fu"># Classification Algorithms</span></span>
<span id="cb13-86"><a href="#cb13-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-87"><a href="#cb13-87" aria-hidden="true" tabindex="-1"></a><span class="fu">## Gaussian Naive Bayes</span></span>
<span id="cb13-88"><a href="#cb13-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-89"><a href="#cb13-89" aria-hidden="true" tabindex="-1"></a>The Gaussian Naive Bayes algorithm from the sklearn library (<span class="co">[</span><span class="ot">see here</span><span class="co">](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html)</span>) utilizes Bayes' theorem assuming the features probability is distributed in a Gaussian or normal fashion, with the variance and mean of each data point calculated for each class. There are a multitude of Naive Bayes classifier algorithms (Bernoulli, Multinomial, etc), but the specific Gaussian probabilistic version used here is especially useful when the values are continuous and expected to follow a Gaussian distribution.</span>
<span id="cb13-90"><a href="#cb13-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-91"><a href="#cb13-91" aria-hidden="true" tabindex="-1"></a>As seen from @fig-nb, the algorithm uses circular decision boundaries to classify each set of labels. The confusion matrix on the right shows that out of 150 samples, it only incorrectly labeled 6 points leading to a mean accuracy of 96%.</span>
<span id="cb13-92"><a href="#cb13-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-95"><a href="#cb13-95" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb13-96"><a href="#cb13-96" aria-hidden="true" tabindex="-1"></a>nb <span class="op">=</span> GaussianNB()</span>
<span id="cb13-97"><a href="#cb13-97" aria-hidden="true" tabindex="-1"></a>nb.fit(x_train, y_train)</span>
<span id="cb13-98"><a href="#cb13-98" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Mean accuracy score: </span><span class="sc">%3.3f%%</span><span class="st">'</span> <span class="op">%</span> (nb.score(x_test,y_test)<span class="op">*</span><span class="dv">100</span>))</span>
<span id="cb13-99"><a href="#cb13-99" aria-hidden="true" tabindex="-1"></a>y_pred<span class="op">=</span>nb.predict(x_train)</span>
<span id="cb13-100"><a href="#cb13-100" aria-hidden="true" tabindex="-1"></a>cm<span class="op">=</span>confusion_matrix(y_train,y_pred,labels<span class="op">=</span>iris.target_names)</span>
<span id="cb13-101"><a href="#cb13-101" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb13-102"><a href="#cb13-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-105"><a href="#cb13-105" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb13-106"><a href="#cb13-106" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb13-107"><a href="#cb13-107" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: Plotting code</span></span>
<span id="cb13-108"><a href="#cb13-108" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-nb</span></span>
<span id="cb13-109"><a href="#cb13-109" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: Gaussian Naive Bayes classification results (with decision boundaries) and confusion matrix </span></span>
<span id="cb13-110"><a href="#cb13-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-111"><a href="#cb13-111" aria-hidden="true" tabindex="-1"></a><span class="co"># decision boundary code adapted from https://hackernoon.com/how-to-plot-a-decision-boundary-for-machine-learning-algorithms-in-python-3o1n3w07</span></span>
<span id="cb13-112"><a href="#cb13-112" aria-hidden="true" tabindex="-1"></a>fig, axs <span class="op">=</span> plt.subplots(<span class="dv">1</span>,<span class="dv">2</span>,figsize <span class="op">=</span>(<span class="dv">8</span>, <span class="dv">5</span>))</span>
<span id="cb13-113"><a href="#cb13-113" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">121</span>)</span>
<span id="cb13-114"><a href="#cb13-114" aria-hidden="true" tabindex="-1"></a>x1grid <span class="op">=</span> np.linspace(x_train[<span class="st">'petal length (cm)'</span>].<span class="bu">min</span>()<span class="op">-</span><span class="fl">.2</span>, x_train[<span class="st">'petal length (cm)'</span>].<span class="bu">max</span>()<span class="op">+</span><span class="fl">.2</span>, <span class="bu">len</span>(x_train))</span>
<span id="cb13-115"><a href="#cb13-115" aria-hidden="true" tabindex="-1"></a>x2grid <span class="op">=</span> np.linspace(x_train[<span class="st">'petal width (cm)'</span>].<span class="bu">min</span>()<span class="op">-</span><span class="fl">.2</span>, x_train[<span class="st">'petal width (cm)'</span>].<span class="bu">max</span>()<span class="op">+</span><span class="fl">.2</span>, <span class="bu">len</span>(x_train))</span>
<span id="cb13-116"><a href="#cb13-116" aria-hidden="true" tabindex="-1"></a>xx, yy <span class="op">=</span> np.meshgrid(x1grid, x2grid)</span>
<span id="cb13-117"><a href="#cb13-117" aria-hidden="true" tabindex="-1"></a>r1, r2 <span class="op">=</span> xx.flatten(), yy.flatten()</span>
<span id="cb13-118"><a href="#cb13-118" aria-hidden="true" tabindex="-1"></a>r1, r2 <span class="op">=</span> r1.reshape((<span class="bu">len</span>(r1), <span class="dv">1</span>)), r2.reshape((<span class="bu">len</span>(r2), <span class="dv">1</span>))</span>
<span id="cb13-119"><a href="#cb13-119" aria-hidden="true" tabindex="-1"></a>grid <span class="op">=</span> np.hstack((r1,r2))</span>
<span id="cb13-120"><a href="#cb13-120" aria-hidden="true" tabindex="-1"></a>y_pred_grid<span class="op">=</span>nb.predict(grid)</span>
<span id="cb13-121"><a href="#cb13-121" aria-hidden="true" tabindex="-1"></a>zz <span class="op">=</span> y_pred_grid.reshape(xx.shape)</span>
<span id="cb13-122"><a href="#cb13-122" aria-hidden="true" tabindex="-1"></a>zz[zz<span class="op">==</span><span class="st">'setosa'</span>]<span class="op">=</span><span class="dv">1</span></span>
<span id="cb13-123"><a href="#cb13-123" aria-hidden="true" tabindex="-1"></a>zz[zz<span class="op">==</span><span class="st">'versicolor'</span>]<span class="op">=</span><span class="dv">2</span></span>
<span id="cb13-124"><a href="#cb13-124" aria-hidden="true" tabindex="-1"></a>zz[zz<span class="op">==</span><span class="st">'virginica'</span>]<span class="op">=</span><span class="dv">3</span></span>
<span id="cb13-125"><a href="#cb13-125" aria-hidden="true" tabindex="-1"></a>xx<span class="op">=</span>np.array(xx,dtype<span class="op">=</span><span class="bu">float</span>)</span>
<span id="cb13-126"><a href="#cb13-126" aria-hidden="true" tabindex="-1"></a>yy<span class="op">=</span>np.array(yy,dtype<span class="op">=</span><span class="bu">float</span>)</span>
<span id="cb13-127"><a href="#cb13-127" aria-hidden="true" tabindex="-1"></a>zz<span class="op">=</span>np.array(zz,dtype<span class="op">=</span><span class="bu">float</span>)</span>
<span id="cb13-128"><a href="#cb13-128" aria-hidden="true" tabindex="-1"></a>plt.scatter(x_train[<span class="st">'petal length (cm)'</span>][y_pred<span class="op">==</span>iris.target_names[<span class="dv">0</span>]],x_train[<span class="st">'petal width (cm)'</span>][y_pred<span class="op">==</span>iris.target_names[<span class="dv">0</span>]],zorder<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb13-129"><a href="#cb13-129" aria-hidden="true" tabindex="-1"></a>plt.scatter(x_train[<span class="st">'petal length (cm)'</span>][y_pred<span class="op">==</span>iris.target_names[<span class="dv">1</span>]],x_train[<span class="st">'petal width (cm)'</span>][y_pred<span class="op">==</span>iris.target_names[<span class="dv">1</span>]],zorder<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb13-130"><a href="#cb13-130" aria-hidden="true" tabindex="-1"></a>plt.scatter(x_train[<span class="st">'petal length (cm)'</span>][y_pred<span class="op">==</span>iris.target_names[<span class="dv">2</span>]],x_train[<span class="st">'petal width (cm)'</span>][y_pred<span class="op">==</span>iris.target_names[<span class="dv">2</span>]],zorder<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb13-131"><a href="#cb13-131" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'petal length (cm)'</span>)</span>
<span id="cb13-132"><a href="#cb13-132" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'petal width (cm)'</span>)</span>
<span id="cb13-133"><a href="#cb13-133" aria-hidden="true" tabindex="-1"></a>plt.legend(iris.target_names)</span>
<span id="cb13-134"><a href="#cb13-134" aria-hidden="true" tabindex="-1"></a>plt.contourf(xx, yy, zz,cmap<span class="op">=</span><span class="st">'RdBu_r'</span>)</span>
<span id="cb13-135"><a href="#cb13-135" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">122</span>)</span>
<span id="cb13-136"><a href="#cb13-136" aria-hidden="true" tabindex="-1"></a>ConfusionMatrixDisplay.from_predictions(y_train,y_pred,ax<span class="op">=</span>axs[<span class="dv">1</span>],colorbar<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb13-137"><a href="#cb13-137" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()  </span>
<span id="cb13-138"><a href="#cb13-138" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb13-139"><a href="#cb13-139" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb13-140"><a href="#cb13-140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-141"><a href="#cb13-141" aria-hidden="true" tabindex="-1"></a><span class="fu">## Gaussian Process Classification</span></span>
<span id="cb13-142"><a href="#cb13-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-143"><a href="#cb13-143" aria-hidden="true" tabindex="-1"></a>The Gaussian Process Classification algorithm from the sklearn library (<span class="co">[</span><span class="ot">see here</span><span class="co">](https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.GaussianProcessClassifier.html)</span>) uses a general form of the Gaussian probability distribution model and is based on Laplace approximation. As it uses Gaussian probability, the model can compute confidence intervals and determine if refitting of a certain section is required based on probability alone. The algorithm is kernel based, meaning multiple types of covariance functions can be utilized and used to optimize model fitting based on the input data. One downside of this algorithm is that is loses efficiency when the number of features grows larger than a few dozen.</span>
<span id="cb13-144"><a href="#cb13-144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-145"><a href="#cb13-145" aria-hidden="true" tabindex="-1"></a>As seen from @fig-gmm, the algorithm uses more linear decision boundaries compared to the above Gaussian Naive to classify each set of labels. The confusion matrix on the right shows that out of 150 samples, it only incorrectly labeled 5 points leading to a mean accuracy of 96.667%. Both of these algorithms are Gaussian in nature, so it is expected that they have similar results.</span>
<span id="cb13-146"><a href="#cb13-146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-149"><a href="#cb13-149" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb13-150"><a href="#cb13-150" aria-hidden="true" tabindex="-1"></a>nb <span class="op">=</span> GaussianProcessClassifier()</span>
<span id="cb13-151"><a href="#cb13-151" aria-hidden="true" tabindex="-1"></a>nb.fit(x_train, y_train)</span>
<span id="cb13-152"><a href="#cb13-152" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Mean accuracy score: </span><span class="sc">%3.3f%%</span><span class="st">'</span> <span class="op">%</span> (nb.score(x_test,y_test)<span class="op">*</span><span class="dv">100</span>))</span>
<span id="cb13-153"><a href="#cb13-153" aria-hidden="true" tabindex="-1"></a>y_pred<span class="op">=</span>nb.predict(x_train)</span>
<span id="cb13-154"><a href="#cb13-154" aria-hidden="true" tabindex="-1"></a>cm<span class="op">=</span>confusion_matrix(y_train,y_pred,labels<span class="op">=</span>iris.target_names)</span>
<span id="cb13-155"><a href="#cb13-155" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb13-156"><a href="#cb13-156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-159"><a href="#cb13-159" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb13-160"><a href="#cb13-160" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb13-161"><a href="#cb13-161" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: Plotting code</span></span>
<span id="cb13-162"><a href="#cb13-162" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-gmm</span></span>
<span id="cb13-163"><a href="#cb13-163" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: Gaussian Process Classifier classification results (with decision boundaries) and confusion matrix </span></span>
<span id="cb13-164"><a href="#cb13-164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-165"><a href="#cb13-165" aria-hidden="true" tabindex="-1"></a><span class="co"># decision boundary code adapted from https://hackernoon.com/how-to-plot-a-decision-boundary-for-machine-learning-algorithms-in-python-3o1n3w07</span></span>
<span id="cb13-166"><a href="#cb13-166" aria-hidden="true" tabindex="-1"></a>fig, axs <span class="op">=</span> plt.subplots(<span class="dv">1</span>,<span class="dv">2</span>,figsize <span class="op">=</span>(<span class="dv">8</span>, <span class="dv">5</span>))</span>
<span id="cb13-167"><a href="#cb13-167" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">121</span>)</span>
<span id="cb13-168"><a href="#cb13-168" aria-hidden="true" tabindex="-1"></a>x1grid <span class="op">=</span> np.linspace(x_train[<span class="st">'petal length (cm)'</span>].<span class="bu">min</span>()<span class="op">-</span><span class="fl">.2</span>, x_train[<span class="st">'petal length (cm)'</span>].<span class="bu">max</span>()<span class="op">+</span><span class="fl">.2</span>, <span class="bu">len</span>(x_train))</span>
<span id="cb13-169"><a href="#cb13-169" aria-hidden="true" tabindex="-1"></a>x2grid <span class="op">=</span> np.linspace(x_train[<span class="st">'petal width (cm)'</span>].<span class="bu">min</span>()<span class="op">-</span><span class="fl">.2</span>, x_train[<span class="st">'petal width (cm)'</span>].<span class="bu">max</span>()<span class="op">+</span><span class="fl">.2</span>, <span class="bu">len</span>(x_train))</span>
<span id="cb13-170"><a href="#cb13-170" aria-hidden="true" tabindex="-1"></a>xx, yy <span class="op">=</span> np.meshgrid(x1grid, x2grid)</span>
<span id="cb13-171"><a href="#cb13-171" aria-hidden="true" tabindex="-1"></a>r1, r2 <span class="op">=</span> xx.flatten(), yy.flatten()</span>
<span id="cb13-172"><a href="#cb13-172" aria-hidden="true" tabindex="-1"></a>r1, r2 <span class="op">=</span> r1.reshape((<span class="bu">len</span>(r1), <span class="dv">1</span>)), r2.reshape((<span class="bu">len</span>(r2), <span class="dv">1</span>))</span>
<span id="cb13-173"><a href="#cb13-173" aria-hidden="true" tabindex="-1"></a>grid <span class="op">=</span> np.hstack((r1,r2))</span>
<span id="cb13-174"><a href="#cb13-174" aria-hidden="true" tabindex="-1"></a>y_pred_grid<span class="op">=</span>nb.predict(grid)</span>
<span id="cb13-175"><a href="#cb13-175" aria-hidden="true" tabindex="-1"></a>zz <span class="op">=</span> y_pred_grid.reshape(xx.shape)</span>
<span id="cb13-176"><a href="#cb13-176" aria-hidden="true" tabindex="-1"></a>zz[zz<span class="op">==</span><span class="st">'setosa'</span>]<span class="op">=</span><span class="dv">1</span></span>
<span id="cb13-177"><a href="#cb13-177" aria-hidden="true" tabindex="-1"></a>zz[zz<span class="op">==</span><span class="st">'versicolor'</span>]<span class="op">=</span><span class="dv">2</span></span>
<span id="cb13-178"><a href="#cb13-178" aria-hidden="true" tabindex="-1"></a>zz[zz<span class="op">==</span><span class="st">'virginica'</span>]<span class="op">=</span><span class="dv">3</span></span>
<span id="cb13-179"><a href="#cb13-179" aria-hidden="true" tabindex="-1"></a>xx<span class="op">=</span>np.array(xx,dtype<span class="op">=</span><span class="bu">float</span>)</span>
<span id="cb13-180"><a href="#cb13-180" aria-hidden="true" tabindex="-1"></a>yy<span class="op">=</span>np.array(yy,dtype<span class="op">=</span><span class="bu">float</span>)</span>
<span id="cb13-181"><a href="#cb13-181" aria-hidden="true" tabindex="-1"></a>zz<span class="op">=</span>np.array(zz,dtype<span class="op">=</span><span class="bu">float</span>)</span>
<span id="cb13-182"><a href="#cb13-182" aria-hidden="true" tabindex="-1"></a>plt.scatter(x_train[<span class="st">'petal length (cm)'</span>][y_pred<span class="op">==</span>iris.target_names[<span class="dv">0</span>]],x_train[<span class="st">'petal width (cm)'</span>][y_pred<span class="op">==</span>iris.target_names[<span class="dv">0</span>]],zorder<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb13-183"><a href="#cb13-183" aria-hidden="true" tabindex="-1"></a>plt.scatter(x_train[<span class="st">'petal length (cm)'</span>][y_pred<span class="op">==</span>iris.target_names[<span class="dv">1</span>]],x_train[<span class="st">'petal width (cm)'</span>][y_pred<span class="op">==</span>iris.target_names[<span class="dv">1</span>]],zorder<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb13-184"><a href="#cb13-184" aria-hidden="true" tabindex="-1"></a>plt.scatter(x_train[<span class="st">'petal length (cm)'</span>][y_pred<span class="op">==</span>iris.target_names[<span class="dv">2</span>]],x_train[<span class="st">'petal width (cm)'</span>][y_pred<span class="op">==</span>iris.target_names[<span class="dv">2</span>]],zorder<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb13-185"><a href="#cb13-185" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'petal length (cm)'</span>)</span>
<span id="cb13-186"><a href="#cb13-186" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'petal width (cm)'</span>)</span>
<span id="cb13-187"><a href="#cb13-187" aria-hidden="true" tabindex="-1"></a>plt.legend(iris.target_names)</span>
<span id="cb13-188"><a href="#cb13-188" aria-hidden="true" tabindex="-1"></a>plt.contourf(xx, yy, zz,cmap<span class="op">=</span><span class="st">'RdBu_r'</span>)</span>
<span id="cb13-189"><a href="#cb13-189" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">122</span>)</span>
<span id="cb13-190"><a href="#cb13-190" aria-hidden="true" tabindex="-1"></a>ConfusionMatrixDisplay.from_predictions(y_train,y_pred,ax<span class="op">=</span>axs[<span class="dv">1</span>],colorbar<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb13-191"><a href="#cb13-191" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()  </span>
<span id="cb13-192"><a href="#cb13-192" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb13-193"><a href="#cb13-193" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb13-194"><a href="#cb13-194" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-195"><a href="#cb13-195" aria-hidden="true" tabindex="-1"></a><span class="fu">## Random Forest Classifier</span></span>
<span id="cb13-196"><a href="#cb13-196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-197"><a href="#cb13-197" aria-hidden="true" tabindex="-1"></a>The Random Forest Classifier as part of the sklearn library (<span class="co">[</span><span class="ot">see here</span><span class="co">](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)</span>) uses decision tree classifiers on multiple parts of the dataset, and then averages scores from each one to maintain a high accuracy and attempt to prevent over fitting. The default arguments were used for this algorithm, but the most important one to call out and be aware of is the number of trees/estimators in the forest is defaulted to 100. Random Forest has the additional benefit of being less computationally expensive as other classification models, such as neural networks.</span>
<span id="cb13-198"><a href="#cb13-198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-199"><a href="#cb13-199" aria-hidden="true" tabindex="-1"></a>As seen from @fig-rf, the algorithm uses boxier decision boundaries than the previous two algorithms to classify each set of labels. The confusion matrix on the right shows that out of 150 samples, it only incorrectly labeled 1 point leading to a mean accuracy of 99.333%. This is by far the best accuracy score of the three algorithms and would be the best model to use for this specific dataset for further work.</span>
<span id="cb13-200"><a href="#cb13-200" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-203"><a href="#cb13-203" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb13-204"><a href="#cb13-204" aria-hidden="true" tabindex="-1"></a>nb <span class="op">=</span> RandomForestClassifier()</span>
<span id="cb13-205"><a href="#cb13-205" aria-hidden="true" tabindex="-1"></a>nb.fit(x_train, y_train)</span>
<span id="cb13-206"><a href="#cb13-206" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Mean accuracy score: </span><span class="sc">%3.3f%%</span><span class="st">'</span> <span class="op">%</span> (nb.score(x_test,y_test)<span class="op">*</span><span class="dv">100</span>))</span>
<span id="cb13-207"><a href="#cb13-207" aria-hidden="true" tabindex="-1"></a>y_pred<span class="op">=</span>nb.predict(x_train)</span>
<span id="cb13-208"><a href="#cb13-208" aria-hidden="true" tabindex="-1"></a>cm<span class="op">=</span>confusion_matrix(y_train,y_pred,labels<span class="op">=</span>iris.target_names)</span>
<span id="cb13-209"><a href="#cb13-209" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb13-210"><a href="#cb13-210" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-213"><a href="#cb13-213" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb13-214"><a href="#cb13-214" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb13-215"><a href="#cb13-215" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: Plotting code</span></span>
<span id="cb13-216"><a href="#cb13-216" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-rf</span></span>
<span id="cb13-217"><a href="#cb13-217" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: Random Forest Classifier classification results (with decision boundaries) and confusion matrix </span></span>
<span id="cb13-218"><a href="#cb13-218" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-219"><a href="#cb13-219" aria-hidden="true" tabindex="-1"></a><span class="co"># decision boundary code adapted from https://hackernoon.com/how-to-plot-a-decision-boundary-for-machine-learning-algorithms-in-python-3o1n3w07</span></span>
<span id="cb13-220"><a href="#cb13-220" aria-hidden="true" tabindex="-1"></a>fig, axs <span class="op">=</span> plt.subplots(<span class="dv">1</span>,<span class="dv">2</span>,figsize <span class="op">=</span>(<span class="dv">8</span>, <span class="dv">5</span>))</span>
<span id="cb13-221"><a href="#cb13-221" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">121</span>)</span>
<span id="cb13-222"><a href="#cb13-222" aria-hidden="true" tabindex="-1"></a>x1grid <span class="op">=</span> np.linspace(x_train[<span class="st">'petal length (cm)'</span>].<span class="bu">min</span>()<span class="op">-</span><span class="fl">.2</span>, x_train[<span class="st">'petal length (cm)'</span>].<span class="bu">max</span>()<span class="op">+</span><span class="fl">.2</span>, <span class="bu">len</span>(x_train))</span>
<span id="cb13-223"><a href="#cb13-223" aria-hidden="true" tabindex="-1"></a>x2grid <span class="op">=</span> np.linspace(x_train[<span class="st">'petal width (cm)'</span>].<span class="bu">min</span>()<span class="op">-</span><span class="fl">.2</span>, x_train[<span class="st">'petal width (cm)'</span>].<span class="bu">max</span>()<span class="op">+</span><span class="fl">.2</span>, <span class="bu">len</span>(x_train))</span>
<span id="cb13-224"><a href="#cb13-224" aria-hidden="true" tabindex="-1"></a>xx, yy <span class="op">=</span> np.meshgrid(x1grid, x2grid)</span>
<span id="cb13-225"><a href="#cb13-225" aria-hidden="true" tabindex="-1"></a>r1, r2 <span class="op">=</span> xx.flatten(), yy.flatten()</span>
<span id="cb13-226"><a href="#cb13-226" aria-hidden="true" tabindex="-1"></a>r1, r2 <span class="op">=</span> r1.reshape((<span class="bu">len</span>(r1), <span class="dv">1</span>)), r2.reshape((<span class="bu">len</span>(r2), <span class="dv">1</span>))</span>
<span id="cb13-227"><a href="#cb13-227" aria-hidden="true" tabindex="-1"></a>grid <span class="op">=</span> np.hstack((r1,r2))</span>
<span id="cb13-228"><a href="#cb13-228" aria-hidden="true" tabindex="-1"></a>y_pred_grid<span class="op">=</span>nb.predict(grid)</span>
<span id="cb13-229"><a href="#cb13-229" aria-hidden="true" tabindex="-1"></a>zz <span class="op">=</span> y_pred_grid.reshape(xx.shape)</span>
<span id="cb13-230"><a href="#cb13-230" aria-hidden="true" tabindex="-1"></a>zz[zz<span class="op">==</span><span class="st">'setosa'</span>]<span class="op">=</span><span class="dv">1</span></span>
<span id="cb13-231"><a href="#cb13-231" aria-hidden="true" tabindex="-1"></a>zz[zz<span class="op">==</span><span class="st">'versicolor'</span>]<span class="op">=</span><span class="dv">2</span></span>
<span id="cb13-232"><a href="#cb13-232" aria-hidden="true" tabindex="-1"></a>zz[zz<span class="op">==</span><span class="st">'virginica'</span>]<span class="op">=</span><span class="dv">3</span></span>
<span id="cb13-233"><a href="#cb13-233" aria-hidden="true" tabindex="-1"></a>xx<span class="op">=</span>np.array(xx,dtype<span class="op">=</span><span class="bu">float</span>)</span>
<span id="cb13-234"><a href="#cb13-234" aria-hidden="true" tabindex="-1"></a>yy<span class="op">=</span>np.array(yy,dtype<span class="op">=</span><span class="bu">float</span>)</span>
<span id="cb13-235"><a href="#cb13-235" aria-hidden="true" tabindex="-1"></a>zz<span class="op">=</span>np.array(zz,dtype<span class="op">=</span><span class="bu">float</span>)</span>
<span id="cb13-236"><a href="#cb13-236" aria-hidden="true" tabindex="-1"></a>plt.scatter(x_train[<span class="st">'petal length (cm)'</span>][y_pred<span class="op">==</span>iris.target_names[<span class="dv">0</span>]],x_train[<span class="st">'petal width (cm)'</span>][y_pred<span class="op">==</span>iris.target_names[<span class="dv">0</span>]],zorder<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb13-237"><a href="#cb13-237" aria-hidden="true" tabindex="-1"></a>plt.scatter(x_train[<span class="st">'petal length (cm)'</span>][y_pred<span class="op">==</span>iris.target_names[<span class="dv">1</span>]],x_train[<span class="st">'petal width (cm)'</span>][y_pred<span class="op">==</span>iris.target_names[<span class="dv">1</span>]],zorder<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb13-238"><a href="#cb13-238" aria-hidden="true" tabindex="-1"></a>plt.scatter(x_train[<span class="st">'petal length (cm)'</span>][y_pred<span class="op">==</span>iris.target_names[<span class="dv">2</span>]],x_train[<span class="st">'petal width (cm)'</span>][y_pred<span class="op">==</span>iris.target_names[<span class="dv">2</span>]],zorder<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb13-239"><a href="#cb13-239" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'petal length (cm)'</span>)</span>
<span id="cb13-240"><a href="#cb13-240" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'petal width (cm)'</span>)</span>
<span id="cb13-241"><a href="#cb13-241" aria-hidden="true" tabindex="-1"></a>plt.legend(iris.target_names)</span>
<span id="cb13-242"><a href="#cb13-242" aria-hidden="true" tabindex="-1"></a>plt.contourf(xx, yy, zz,cmap<span class="op">=</span><span class="st">'RdBu_r'</span>)</span>
<span id="cb13-243"><a href="#cb13-243" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">122</span>)</span>
<span id="cb13-244"><a href="#cb13-244" aria-hidden="true" tabindex="-1"></a>ConfusionMatrixDisplay.from_predictions(y_train,y_pred,ax<span class="op">=</span>axs[<span class="dv">1</span>],colorbar<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb13-245"><a href="#cb13-245" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()  </span>
<span id="cb13-246"><a href="#cb13-246" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb13-247"><a href="#cb13-247" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb13-248"><a href="#cb13-248" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-249"><a href="#cb13-249" aria-hidden="true" tabindex="-1"></a><span class="fu"># Results and Conclusion</span></span>
<span id="cb13-250"><a href="#cb13-250" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-251"><a href="#cb13-251" aria-hidden="true" tabindex="-1"></a>The three classification algorithms used in this blog post used a relatively small dataset to attempt and match the original labels. Both Gaussian classification models (Gaussian Naive Bayes and Gaussian Process Classification) performed similarly and had \~96% accuracy. The Random Forest classification algorithm performed much better than the previous two, with a mean accuracy score <span class="sc">\&gt;</span> 99% and only misidentified a single data point.</span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->



</body></html>