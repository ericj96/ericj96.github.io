[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Blog",
    "section": "",
    "text": "Hyperparameter Tuning\n\n\n\n\n\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nOct 6, 2023\n\n\nEric Jackson\n\n\n\n\n\n\n  \n\n\n\n\nAnomaly Detection on Spacecraft Telemetry\n\n\n\n\n\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nSep 8, 2023\n\n\nEric Jackson\n\n\n\n\n\n\n  \n\n\n\n\nData Preprocessing\n\n\n\n\n\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nSep 8, 2023\n\n\nEric Jackson\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Anomaly Detection on Spacecraft Telemetry",
    "section": "",
    "text": "Every spacecraft that is launched has some form of onboard anomaly responses for most known failure cases in order to safe the vehicle. Normally these are simple low/high limits set for certain monitors (temperature, voltage, etc) with a corresponding response, whether that be a simple visual alarm or powering off certain equipment.\nThe problem with anomalies in space is that they can be incredibly hard to predict, as multiple components can react slightly out of family to create a larger issue. Spacecraft will also generate a massive amount of data the longer they are on orbit, and manually looking and trending this data from a human standpoint can miss certain anomalies. But, this large amount of data makes them perfect for utilizing machine learning. Machine learning would allow for these anomalies to not only be identified, but also potentially predicted and prevented, allowing the spacecraft to stay in mission over potentially high priority targets (depending on the payload/mission). An automatic response to a predicted anomaly would limit both downtime and human interaction, as the investigation and implementation can take hours to days before returning to mission.\n\n\n\nExample of anomaly in telemetry data"
  },
  {
    "objectID": "posts/Topic_2/index.html",
    "href": "posts/Topic_2/index.html",
    "title": "Hyperparameter Tuning",
    "section": "",
    "text": "When a machine learning model is being trained, one of the most important parts of the process is choosing valid hyperparameters. Hyperparameters are parameters whose value can be used to control the learning process, while other parameters are simply derived during the training process. These hyperparameters do not necessarily impact or influence the performance of the model, but impact the speed and quality of the learning process. As such, the hyperparameters are set prior to training the model and not during.\nExamples of common hyperparameters include:\n\nLearning rate and network size in Long short-term memory (LSTM)\nk in k-nearest neighbors\nThe penalty in most classifier methods"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/Topic_3/index.html",
    "href": "posts/Topic_3/index.html",
    "title": "Data Preprocessing",
    "section": "",
    "text": "Background"
  },
  {
    "objectID": "posts/post-with-code/index.html#preprocessing",
    "href": "posts/post-with-code/index.html#preprocessing",
    "title": "Anomaly Detection on Spacecraft Telemetry",
    "section": "Preprocessing",
    "text": "Preprocessing\nMany spacecraft constellations have decades of on orbit telemetry available, but is mostly proprietary and not available for public use. LASP and NASA releases subsets of data to the public, and this is what was used for this blog post. Reaction wheel temperatures, battery temperatures and voltages, and total bus current datasets were used, each having 750,000+ samples of data over ~14.5 years. Because ARIMA requires the data to be stationary, each of the datasets is first sampled down to a daily mean which brings the size down to only 5346 data points. This will allow for much faster processing. To increase the number of exogenous features, each dataset is also turned into sets of rolling mean and rolling standard deviation in windows of 3, 7, and 30 days.\nUnfold the below code to see the setup of the data and how it is preprocessed as mentioned above.\nA visualization of the separation between training and test data can be seen in in Figure 1, with the first 75% used for training and the remaining 25% used for test data.\n\n\nCode\nimport os\nimport datetime\nfrom math import sqrt\nimport pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot\nfrom statsmodels.tsa.arima_model import ARIMA\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\nfrom statsmodels.tsa.stattools import acf, pacf\nfrom statsmodels.tsa.stattools import adfuller\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nfrom statsmodels.tsa.arima_model import ARIMAResults\nfrom sklearn.metrics import mean_squared_error\nimport sklearn.svm as svm\nimport matplotlib.pyplot as plt\nimport math\nimport warnings\nwarnings.filterwarnings('ignore', '[\\s\\w\\W]*non-unique[\\s\\w\\W]*', DeprecationWarning)\n\ndf=pd.read_csv('./WheelTemperature.csv')\ndf_battemp=pd.read_csv('./BatteryTemperature.csv')\ndf_buscurrent=pd.read_csv('./TotalBusCurrent.csv')\ndf_busvolt=pd.read_csv('./BusVoltage.csv')\n\ndf_battemp.Date = pd.to_datetime(df_battemp.Date, format=\"%m/%d/%Y %H:%M\")\ndf_buscurrent.Date = pd.to_datetime(df_buscurrent.Date, format=\"%m/%d/%Y\")\ndf_busvolt.Date=pd.to_datetime(df_busvolt.Date, format=\"%m/%d/%Y %H:%M\")\ndf.Date = pd.to_datetime(df.Date, format=\"%m/%d/%Y %H:%M\")\n\ndf_battemp=df_battemp.resample('1D',on='Date').mean()\ndf_buscurrent=df_buscurrent.resample('1D',on='Date').mean()\ndf_busvolt=df_busvolt.resample('1D',on='Date').mean()\ndf_busvolt=df_busvolt.loc['2004-02-13':]\ndf=df.resample('1D',on='Date').mean()\n\ndf=pd.concat([df,df_battemp,df_buscurrent,df_busvolt],axis=1)\ndf['Date']=df.index\n\nlag_features = [\"High\", \"Low\", \"Volume\", \"Turnover\", \"NumTrades\"]\nlag_features=[\"High\",\"Temp\",\"Current\",\"Voltage\"]\nwindow1 = 3\nwindow2 = 7\nwindow3 = 30\n\ndf_rolled_3d = df[lag_features].rolling(window=window1, min_periods=0)\ndf_rolled_7d = df[lag_features].rolling(window=window2, min_periods=0)\ndf_rolled_30d = df[lag_features].rolling(window=window3, min_periods=0)\n\ndf_mean_3d = df_rolled_3d.mean().shift(1).reset_index()\ndf_mean_7d = df_rolled_7d.mean().shift(1).reset_index()\ndf_mean_30d = df_rolled_30d.mean().shift(1).reset_index()\n\ndf_std_3d = df_rolled_3d.std().shift(1).reset_index()\ndf_std_7d = df_rolled_7d.std().shift(1).reset_index()\ndf_std_30d = df_rolled_30d.std().shift(1).reset_index()\n\ndf_mean_3d.set_index(\"Date\", drop=True, inplace=True)\ndf_mean_7d.set_index(\"Date\", drop=True, inplace=True)\ndf_mean_30d.set_index(\"Date\", drop=True, inplace=True)\ndf_std_3d.set_index(\"Date\", drop=True, inplace=True)\ndf_std_7d.set_index(\"Date\", drop=True, inplace=True)\ndf_std_30d.set_index(\"Date\", drop=True, inplace=True)\n\nfor feature in lag_features:\n    \n    df[f\"{feature}_mean_lag{window1}\"] = df_mean_3d[feature]\n    df[f\"{feature}_mean_lag{window2}\"] = df_mean_7d[feature]\n    df[f\"{feature}_mean_lag{window3}\"] = df_mean_30d[feature]\n    \n    df[f\"{feature}_std_lag{window1}\"] = df_std_3d[feature]\n    df[f\"{feature}_std_lag{window2}\"] = df_std_7d[feature]\n    df[f\"{feature}_std_lag{window3}\"] = df_std_30d[feature]\n\ndf.Date = pd.to_datetime(df.Date, format=\"%m/%d/%Y %H:%M\")\ndf[\"month\"] = df.Date.dt.month\ndf[\"week\"] = df.Date.dt.isocalendar().week.astype(np.int64)\ndf[\"day\"] = df.Date.dt.day\ndf[\"day_of_week\"] = df.Date.dt.dayofweek\ndf.set_index(\"Date\", drop=True, inplace=True)\ndf.fillna(df.mean(), inplace=True)\n\ndata=df\ndata.index = pd.to_datetime(data.index)\ndata=data.resample('1D').mean()\ndf_train=data.iloc[0:math.floor(len(data)*.75),:]\ndf_valid=data.iloc[math.floor(len(data)*.75):,:]\n\nexogenous_features=['High_mean_lag3', 'High_mean_lag7',\n       'High_mean_lag30', 'High_std_lag3', 'High_std_lag7', 'High_std_lag30',\n       'Temp_mean_lag3', 'Temp_mean_lag7', 'Temp_mean_lag30', 'Temp_std_lag3',\n       'Temp_std_lag7', 'Temp_std_lag30', 'Current_mean_lag3',\n       'Current_mean_lag7', 'Current_mean_lag30', 'Current_std_lag3',\n       'Current_std_lag7', 'Current_std_lag30', 'Voltage_mean_lag3',\n       'Voltage_mean_lag7', 'Voltage_mean_lag30', 'Voltage_std_lag3',\n       'Voltage_std_lag7', 'Voltage_std_lag30', 'month', 'week', 'day',\n       'day_of_week']\n\n\n\n\n\n\n\nFigure 1: Training data is first 75% of wheel temperature data, with the remaining 25% used as the test data for verification"
  },
  {
    "objectID": "posts/post-with-code/index.html#truth-data",
    "href": "posts/post-with-code/index.html#truth-data",
    "title": "Anomaly Detection on Spacecraft Telemetry",
    "section": "Truth Data",
    "text": "Truth Data\nIn order to determine the accuracy of the anomaly detection methods used below, a set of truth data points needed to be manually chosen. These points were identified to be points in time where an anomaly took place based on personal experience of operational spacecraft data. 115 out of 1137 total points were marked as anomalous. Figure 2 identifies the anomalies, marked in red.\n\n\nCode\ndf_truth=pd.read_csv('./truth.csv')\ndf_truth.Date = pd.to_datetime(df_truth.Date, format=\"%m/%d/%Y\")\ndf_truth.set_index(\"Date\", drop=True, inplace=True)\nanom=df_truth['Anom']\nanom=anom.map(lambda val:1 if val==-1 else 0)\na=df_truth.loc[df_truth['Anom']==1,['High']]\nfig, ax = plt.subplots(figsize=(10,6))\nax.plot(df_truth.index,df_truth['High'], color='black', label = 'ARIMA')\nax.scatter(a.index,a.values, color='red', label = 'Anomaly')\nplt.legend(['Wheel Temperature','Anomaly'])\nplt.ylabel('Temperature (C)')\nplt.title('Truth Anomalies')\nplt.show()\n\n\n\n\n\nFigure 2: Set of anomalous data points to be used as truth"
  },
  {
    "objectID": "posts/Topic_2/index.html#grid-search",
    "href": "posts/Topic_2/index.html#grid-search",
    "title": "Hyperparameter Tuning",
    "section": "Grid Search",
    "text": "Grid Search\n\nfrom sklearn.model_selection import GridSearchCV \n\n# defining parameter range \nparam_grid = {'C': [0.1, 1, 10, 100, 1000,10000], \n            'gamma': [1, 0.1, 0.01, 0.001, 0.0001,0.00001], \n            'kernel': ['rbf']} \n\ngrid = GridSearchCV(SVC(), param_grid,refit = True, verbose = 1) \n\n# fitting the model for grid search \ngrid.fit(X_train, y_train) \n\ngrid_predictions = grid.predict(X_test) \n\n# print classification report \nprint(classification_report(y_test, grid_predictions)) \nprint('%f\\n%s' % (grid.best_score_,grid.best_params_))\n\nFitting 5 folds for each of 36 candidates, totalling 180 fits\n              precision    recall  f1-score   support\n\n           0       0.94      0.89      0.91        66\n           1       0.94      0.96      0.95       105\n\n    accuracy                           0.94       171\n   macro avg       0.94      0.93      0.93       171\nweighted avg       0.94      0.94      0.94       171\n\n0.959747\n{'C': 100, 'gamma': 1e-05, 'kernel': 'rbf'}"
  },
  {
    "objectID": "posts/Topic_2/index.html#random-search",
    "href": "posts/Topic_2/index.html#random-search",
    "title": "Hyperparameter Tuning",
    "section": "Random Search",
    "text": "Random Search\n\nfrom sklearn.model_selection import RandomizedSearchCV\nclf = RandomizedSearchCV(estimator=SVC(),\n                   param_distributions=param_grid,\n                   verbose=1)\n                   \nclf.fit(X_train, y_train) \nclf_predictions = clf.predict(X_test) \n\n# print classification report \nprint(classification_report(y_test, clf_predictions)) \nprint('%f\\n%s' % (clf.best_score_,clf.best_params_))\n\nFitting 5 folds for each of 10 candidates, totalling 50 fits\n              precision    recall  f1-score   support\n\n           0       0.95      0.91      0.93        66\n           1       0.94      0.97      0.96       105\n\n    accuracy                           0.95       171\n   macro avg       0.95      0.94      0.94       171\nweighted avg       0.95      0.95      0.95       171\n\n0.952278\n{'kernel': 'rbf', 'gamma': 1e-05, 'C': 1000}"
  },
  {
    "objectID": "posts/Topic_2/index.html#bayesian-optimization",
    "href": "posts/Topic_2/index.html#bayesian-optimization",
    "title": "Hyperparameter Tuning",
    "section": "Bayesian Optimization",
    "text": "Bayesian Optimization\n\ndef warn(*args, **kwargs):\n    pass\nimport warnings\nwarnings.warn = warn\nfrom pandas import read_csv\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom skopt import BayesSearchCV\n\nbayes = BayesSearchCV(SVC(), param_grid) \n\n# fitting the model for grid search \nbayes.fit(X_train, y_train) \n\nbayes_predictions = bayes.predict(X_test) \n\n# print classification report \nprint(classification_report(y_test, bayes_predictions)) \nprint('%f\\n%s' % (bayes.best_score_,bayes.best_params_))\n\n              precision    recall  f1-score   support\n\n           0       0.94      0.89      0.91        66\n           1       0.94      0.96      0.95       105\n\n    accuracy                           0.94       171\n   macro avg       0.94      0.93      0.93       171\nweighted avg       0.94      0.94      0.94       171\n\n0.959747\nOrderedDict([('C', 100.0), ('gamma', 1e-05), ('kernel', 'rbf')])\n\n\n\nimport matplotlib.pyplot as plt\nfrom skopt.plots import plot_convergence\nres=pd.DataFrame(bayes.cv_results_)\nres2=pd.DataFrame(grid.cv_results_)\nres3=pd.DataFrame(clf.cv_results_)\nres.mean_test_score.plot(figsize=(10,10))\nres2.mean_test_score.plot(figsize=(10,10))\nres3.mean_test_score.plot(figsize=(10,10))\nplt.legend(['Bayes','Grid','Random'])\nplt.show()\nplt.clf()\n\n\n\n\n&lt;Figure size 672x480 with 0 Axes&gt;"
  }
]